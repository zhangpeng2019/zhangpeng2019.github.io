<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Artificial Intelligence on 陈巧倩</title>
    <link>https://www.chenqiaoqian.com/categories/artificial-intelligence/</link>
    <description>Recent content in Artificial Intelligence on 陈巧倩</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sat, 22 Jul 2023 11:13:34 +0800</lastBuildDate><atom:link href="https://www.chenqiaoqian.com/categories/artificial-intelligence/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>解密游戏中关卡难度的统计建模-中文版</title>
      <link>https://www.chenqiaoqian.com/2023/07/22/2023-07-22-Statistical.Modelling.of.Level.Difficulty.in.Puzzle.Games/</link>
      <pubDate>Sat, 22 Jul 2023 11:13:34 +0800</pubDate>
      
      <guid>https://www.chenqiaoqian.com/2023/07/22/2023-07-22-Statistical.Modelling.of.Level.Difficulty.in.Puzzle.Games/</guid>
      <description>&lt;p&gt;作者Jeppe Theiss Kristensen、Arturo Valdivia*、Paolo Burelli&lt;/p&gt;
&lt;h1 id=&#34;摘要&#34;&gt;摘要 &lt;a href=&#34;#%e6%91%98%e8%a6%81&#34; class=&#34;anchor&#34;&gt;🔗&lt;/a&gt;&lt;/h1&gt;&lt;p&gt;成功和准确地对关卡难度进行建模是玩家体验操作化的基本组成部分，因为难度是内容设计和调整中最重要且常用的信号之一。在具有中间里程碑的游戏中，如可完成的区域或关卡，难度通常由完成的概率或完成率来定义；然而，这种操作化存在局限性，因为它并未描述玩家在该区域内的行为。
在这项研究工作中，我们为解密游戏形式化了一个超越经典成功概率的关卡难度模型。我们通过使用参数统计模型描述游戏关卡内执行的动作分布来实现这一点，从而创建了一个更丰富的难度描述符。该模型在由触觉游戏收集的《Lily&amp;rsquo;s Garden》游戏数据集上进行拟合和评估，评估结果显示该模型能够描述和解释绝大多数关卡的难度。
关键词—玩家建模、难度建模、游戏设计、动态游戏适应性、生存分析&lt;/p&gt;
&lt;h1 id=&#34;i-引言&#34;&gt;I. 引言 &lt;a href=&#34;#i-%e5%bc%95%e8%a8%80&#34; class=&#34;anchor&#34;&gt;🔗&lt;/a&gt;&lt;/h1&gt;&lt;p&gt;游戏设计的一个核心方面是难度及其对玩家体验的影响——如果游戏太容易，玩家就不会足够投入其中；如果游戏太难，玩家会感到沮丧，导致他们放弃游戏。在由离散任务或关卡组成的游戏中，管理难度的常见方法是通过控制玩家完成任务或关卡所需的资源，例如，可用的行动次数或解决谜题的时间。平衡关卡中可用资源的正确数量以获得所需的难度是一项复杂的任务，通常依赖设计师将难度的抽象描述与玩家行为和关卡中可控组件相关联的能力。
例如，在提供玩家有限行动或移动次数来完成每个关卡的解密游戏中，如三消或泡泡射击风格的游戏，描述难度的直接方式是测量玩家平均完成一个关卡需要多少尝试次数。这个数量通常被称为尝试完成次数，其乘法倒数是我们所说的完成率。这个定义对于识别玩家可能感到困惑并因此停止玩游戏的关卡，控制游戏内容的消耗速率，甚至启用不同的货币化策略是有用的。然而，这样的描述符只是以聚合的方式考虑数据，因此缺乏可能会告诉关于改变行动限制的影响或玩家接近完成的程度等细节的细粒度。这使得其在表达上相对有限，给设计师提供了很少关于如何调整难度的信息，因此将关卡调整的任务转变为试错程序。
在当前发布的大多数解密游戏中，成功或失败不是关于玩家在游戏中行为的唯一数据；通常会跟踪执行的动作摘要和使用的资源。如果正确建模，这些信息有潜力成为关卡难度的一个更丰富描述符的基础。特别是，玩家在尝试中使用的动作数量既有助于描述他们在关卡内的进展，又直接与一个重要的关卡设计方面——移动次数限制相关。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.chenqiaoqian.com/2023-07-22-Statistical.Modelling.of.Level.Difficulty.in.Puzzle.Games/1.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;图1. 玩家完成数据中一个关卡所花费的动作数量的直方图。在动作限制接近M = 32时，可以清楚地看到分布中的明显截断效应。如果我们能够准确估计完整的分布（由红色曲线表示），则可以计算使用不同动作限制的完成率。&lt;/p&gt;
&lt;p&gt;完成一个关卡所需的动作数量取决于许多因素，如玩家技能、关卡设置和运气。这导致玩家在每个关卡上花费的动作呈现出一定的分布（见图1）。本文的核心思想是，通过对这种动作分布的建模和理解，我们不仅可以评估完成率，还可以估计设计动作的影响，如改变移动限制，并更深入地了解玩家面临的挑战。
为实现这一目标，玩家行为模型需要既准确又可解释。因此，在这项研究工作中，我们研究了应用参数统计模型来表示潜在动作分布的方法。我们讨论了如何使用负二项分布对这种行为进行建模，并对这种建模方法在触觉游戏的热门移动解密游戏《Lily&amp;rsquo;s Garden》的数据集上进行了实证研究，并呈现和讨论了研究结果。&lt;/p&gt;
&lt;h1 id=&#34;ii-相关工作&#34;&gt;II. 相关工作 &lt;a href=&#34;#ii-%e7%9b%b8%e5%85%b3%e5%b7%a5%e4%bd%9c&#34; class=&#34;anchor&#34;&gt;🔗&lt;/a&gt;&lt;/h1&gt;&lt;p&gt;Flow [4] 描述了任务难度和用户技能匹配，从而产生引人入胜的游戏体验的心理状态。虽然难度可以分解为多个子组件（如认知、情感等 [6]），在需要将难度操作化的情况下，例如用于动态难度调整或自动化游戏测试，通常使用任务成功的概率作为难度的客观衡量标准 [5]，[7]，[9]，[13]，[15]，[17]。这种解释得到了 Pedersen 等人的支持 [16]，他们研究了超级马里奥兄弟中玩家情绪与关卡特征之间的相关性。在这里，感到受挑战的最大因素是关卡的完成率或类似的失败方面，如死亡次数。
在这项工作中，我们采用类似的概率定义：关卡的难度由胜率给出，实际上是完成率，可以计算为给定关卡已完成的次数除以该关卡上总尝试次数。然而，虽然将难度描述为完成率是直观的，但它并不能提供更深入和可操作的问题理解，例如，强加时间或行动限制如何影响完成率，或者玩家接近完成的程度。这种数据的性质是被审查的，因为我们没有关于完整游戏过程的信息，因此为了从中汲取应对方法的灵感，我们可以参考生存分析 [14]。&lt;/p&gt;
&lt;p&gt;生存分析是统计学的一个分支，专注于估计未见或审查的数据，通常用于估计事件发生的时间。有多个例子使用这种方法来使用参数分布描述玩家行为：Feng 等人 [8] 使用广义威布尔分布来建模在线会话长度，Bauckhage 等人 [2] 测试了各种分布，包括威布尔分布和泊松-伽玛分布，以估计人们失去对游戏兴趣的时间。生存分析方法已被用于描述 [10] 中与游戏玩法相关的行为，在该研究中，作者调查了游戏 Flappy Bird 中关卡的感知难度的操作化。通过使用玩家和游戏测试 AI 数据，他们计算了一个经验生存函数 S(x)，描述了在一个关卡中达到给定长度的尝试的分布。从中，危险函数可以用作感知难度的指标。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.chenqiaoqian.com/2023-07-22-Statistical.Modelling.of.Level.Difficulty.in.Puzzle.Games/2.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;图2. Lily&amp;rsquo;s Garden 中一个关卡的示例。关卡目标在左侧指定，在游戏中的助推器在右侧。这些游戏中的助推器是非常强大的助推器，可以让玩家更轻松地完成关卡。&lt;/p&gt;
&lt;p&gt;本文呈现的工作与这些最近的研究具有相似的性质，即我们试图通过使用参数统计分布来操作化和抽象游戏玩法的一个方面——即关卡难度。关键的不同点在于，本文提出的模型既建立在大量真实玩家游戏数据的基础上，又在此基础上进行了评估；此外，我们提出了一个描述难度操作化、确定适当分布并评估其有效性的一般性框架。&lt;/p&gt;
&lt;h1 id=&#34;iii-方法&#34;&gt;III. 方法 &lt;a href=&#34;#iii-%e6%96%b9%e6%b3%95&#34; class=&#34;anchor&#34;&gt;🔗&lt;/a&gt;&lt;/h1&gt;&lt;p&gt;让我们从简要描述益智游戏机制开始这一部分。每个关卡要求玩家在预定的最大行动次数或移动次数M内收集一系列目标。每次移动包括通过点击其中一个相邻的棋盘块来消除一组相邻的棋盘块。通过同时匹配至少5个棋盘块的组来创建清除棋盘大面积的更强大的棋盘块是可能的。图2显示了一个关卡的示例。
如果玩家在不超过M次移动的情况下完成了所有关卡目标，那么我们称该尝试是成功的，玩家将进入下一个关卡。因此，每个玩家最多可以完成每个关卡一次。现在，如果玩家在没有完成所有关卡目标的情况下使用了所有允许的移动次数M，那么我们称该尝试是失败的。在这种情况下，玩家可以花费虚拟货币获得额外的移动次数（例如，+5），或者决定再尝试一次以牺牲一条生命。这些生命会随着时间自动恢复，并且通常每个玩家在任何给定时间最多可以获得5条生命。
对于这项研究，我们使用了从2020年06月01日至2021年01月01日之间收集的L = 4000个关卡的数据样本。对于每个关卡，每次尝试的可用数据包括使用的移动次数以及尝试是否成功。首先进行了数据清洗步骤，通过排除所有不完整的尝试，即由于游戏中的技术问题或玩家故意退出游戏而提前终止的尝试。我们还排除了使用特殊游戏内助推器的尝试，这些助推器通常会增加在移动次数限制M内完成的尝试的次数k = 0, 1, 2。最终的输入数据集包括完成关卡所使用的移动次数的频率（参见图1）和总体完成率，定义为成功尝试占总尝试次数的百分比，每个关卡平均有350,000次成功尝试。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.chenqiaoqian.com/2023-07-22-Statistical.Modelling.of.Level.Difficulty.in.Puzzle.Games/3.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;图3. 展示完成一个关卡所使用的移动次数的观察频率。垂直虚线表示移动次数限制设置为M = 15。拟合曲线用虚线标记。左上角的子图表明观察到的频率几乎呈线性增长，导致拟合负二项分布的左尾。&lt;/p&gt;
&lt;p&gt;该方法的目标是确定一个参数分布，该分布能够很好地适应完成一个关卡所使用的移动次数，即在移动次数限制M∗规定的截断点之上。拟合的曲线应该与观察到的频率相匹配，并且该曲线下的面积应该与观察到的完成率相匹配。作为说明，图3描述了拟合分布能够很好地描述观察到的频率，但未能匹配完成率的不良情况。我们可以期望这种情况发生，例如当观察到的频率的稳定增长几乎是线性的，因此被校准为分布的左尾时。这些想法在下面得到了形式化。
备注。在这里我们注意到，对于其他类型的游戏，输入数据集的定义将是类似的，例如，通过交换完成关卡所使用的移动次数的角色，改为完成任务所需的时间单位。&lt;/p&gt;
&lt;h2 id=&#34;a-模型参数的校准&#34;&gt;A. 模型参数的校准 &lt;a href=&#34;#a-%e6%a8%a1%e5%9e%8b%e5%8f%82%e6%95%b0%e7%9a%84%e6%a0%a1%e5%87%86&#34; class=&#34;anchor&#34;&gt;🔗&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;给定一个具有移动次数限制M∗的关卡，让我们用Fˆ表示完成该关卡所使用的移动次数的经验分布。让ˆc表示观察到的关卡完成率，即在最多M∗次移动内完成关卡的尝试的百分比。如图1所示，经验移动分布Fˆ在右侧被M∗截断，但我们假设这些数据对应于基础未截断分布F的受限观察。让我们假设Fˆ和F具有概率密度函数，并分别用fˆ和f表示。
在这些术语中，我们的目标是找到分布F的一个参数模型，使得满足以下两个条件：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.chenqiaoqian.com/2023-07-22-Statistical.Modelling.of.Level.Difficulty.in.Puzzle.Games/4.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;图4. 展示完成关卡所剩移动次数的均值和方差之间的线性关系。&lt;/p&gt;
&lt;p&gt;条件1. 拟合分布F在整个范围（0，M∗]内紧密地跟随经验分布Fˆ。
条件2. 量F（M∗）近似于观察到的完成率ˆc。
在本文中，我们将条件2仅视为验证步骤；也就是说，我们不将此条件明确强制作为校准算法的一部分。决定背后的理由是，我们的目标是在这里建立一个基准，仅通过拟合截断数据来解释多少。换句话说，我们正在评估条件1能够确保条件2同样得到满足的程度。&lt;/p&gt;
&lt;p&gt;在本文中，我们将条件2仅视为验证步骤；也就是说，我们不会明确将此条件作为校准算法的一部分。决定背后的理由是，我们的目标是建立一个基准，仅通过拟合截断数据来解释多少。换句话说，我们正在评估条件1能够确保条件2同样得到满足的程度。
现在让我们描述模型参数的校准策略。给定分布F的一个参数模型，我们通过在范围（0，M∗]上应用非线性最小二乘（NLLS）回归来获得相应的参数集θ，在这个范围内我们可以完全观察到Fˆ。这种方法需要一个参数θ的初始猜测θ0作为输入，如果选择不当，可能会因拟合不佳而导致假阴性。为了最小化这种风险，我们通过解决以下优化问题来选择初始猜测：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.chenqiaoqian.com/2023-07-22-Statistical.Modelling.of.Level.Difficulty.in.Puzzle.Games/5.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;这里，Θ表示初始猜测θ0的搜索空间；f(θ0)是我们通过使用初始猜测θ0从NLLS得到的分布；D是分布Fˆ和F(θ0)在范围（0，M]上的距离。在这里，我们将使用Kolmogorov-Smirnov距离（参见[1]），在这种情况下，它简单地由表示：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.chenqiaoqian.com/2023-07-22-Statistical.Modelling.of.Level.Difficulty.in.Puzzle.Games/6.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;请注意，在这些术语中，条件1可以重写为D(fˆ，f(θ0∗())) &amp;lt; δ，其中δ足够小，比如说5%。`&lt;/p&gt;
&lt;h2 id=&#34;b-底层参数分布的要求&#34;&gt;B. 底层参数分布的要求 &lt;a href=&#34;#b-%e5%ba%95%e5%b1%82%e5%8f%82%e6%95%b0%e5%88%86%e5%b8%83%e7%9a%84%e8%a6%81%e6%b1%82&#34; class=&#34;anchor&#34;&gt;🔗&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;我们的目标分布（即，完成级别所需的移动）仅采用非负整数值。因此，为了拟合参数模型，我们可以使用非负整数值分布（例如，负二项分布），或者可以使用非负连续分布的离散化（例如，伽玛分布）。
为了限定我们可以用于分析的潜在分布列表，我们首先查看图4所示的模式，该图表明完成级别所需的剩余移动次数的均值和方差之间存在强烈的线性关系。更具体地说：让M (n, i)表示第i个玩家在第n次尝试通过级别时剩余的移动次数。该图的每个点对应于我们样本中级别 = 1，&amp;hellip;，L（L = 4000）中的一个，坐标轴x和y分别等于M (n, i)的均值µ和方差σ，其中n和i变化在观察期间发生的所有尝试中。虚线显示了对σ2关于µ进行线性回归的结果，没有截距 - 即，我们考虑形式为σ2 ≈ ψµ的模型。这种拟合的好坏（即，R2 ≈ 85%，p值 &amp;lt; 10^(-16)）表明了均值µ和方差σ2之间的强线性关系，进一步暗示了我们对M的参数模型应满足的必要条件。&lt;/p&gt;
&lt;p&gt;C. 负二项分布作为基准线
根据以上内容，很明显，最自然且非平凡的起点是考虑负二项分布，因为它是一个众所周知的非负整数值分布，展现出其均值和方差之间的线性关系：
f(m) :=  m + n m - 1  (1 - p)^n p^m，对于m = 0, 1, 2, &amp;hellip; 至于初始猜测的搜索空间，我们将使用Θ := [1, 10M] × [0.001, 0.999]。 这里有两点需要注意：首先，注意到负二项分布也被称为Poisson-gamma分布，因为它等价于强度参数λ的Poisson分布，其中λ本身可以通过遵循伽马分布而成为随机变量。 其次，一个更复杂的方法是使用Tweedie分布的离散化，对于Tweedie分布，众所周知σ2 = ψµp，或者甚至是Poisson-Tweedie分布，对于该分布σ2 = µ + ψµp[3]，[11]。然而，我们将这个调查留给未来的工作，因为我们的初步探索（参见图4）表明，考虑一个离散参数p = 1可能已经提供了一个非常好的起点。&lt;/p&gt;
&lt;h1 id=&#34;iv-结果&#34;&gt;IV. 结果 &lt;a href=&#34;#iv-%e7%bb%93%e6%9e%9c&#34; class=&#34;anchor&#34;&gt;🔗&lt;/a&gt;&lt;/h1&gt;&lt;p&gt;为了评估我们方法的有效性，我们在谜题游戏《Lily&amp;rsquo;s Garden》的4000个级别上进行了测试：首先，我们分析了所有级别上拟合分布参数的整体结果。在第二步中，基于前一节中描述的关于拟合分布的条件，我们讨论了生成模型拟合的好坏，从而评估模型描述玩家行为的能力。最后，我们验证模型是否能够描述级别的难度经典定义 - 即完成概率 - 以及前述行为。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.chenqiaoqian.com/2023-07-22-Statistical.Modelling.of.Level.Difficulty.in.Puzzle.Games/7.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;图5. 拟合参数p和n的对数线性图，每个级别对应一个。颜色表示玩过该级别的用户数量。&lt;/p&gt;
&lt;h2 id=&#34;a-分布参数&#34;&gt;A. 分布参数 &lt;a href=&#34;#a-%e5%88%86%e5%b8%83%e5%8f%82%e6%95%b0&#34; class=&#34;anchor&#34;&gt;🔗&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;图5显示了从在谜题游戏《Lily&amp;rsquo;s Garden》的4000个级别上执行算法中获得的拟合参数。每个点代表一个负二项模型的参数（n，p），该模型适用于完成每个级别 = 1, 2, &amp;hellip;, L所使用的移动的分布。可以看到，大多数（即83%）的级别都落在由0.001 &amp;lt; p ≤ 1和1 ≤ n ≤ 200（）定义的中心簇内。对于这个中心簇，显然参数（n，p）遵循对数线性关系log(n) = ap + b关系（R2 = 87%），其中a和b是不依赖于级别的全局常数。这表明级别的移动分布可能由单个参数驱动，这将使级别设计者能够轻松地将级别相互比较。 为此，可以考虑所谓的尺度参数（ϑ），它描述了分布的扩展性 - 即，尺度参数越大，分布越分散。这个数值参数通常在概率分布的参数族的背景下考虑，在负二项分布的情况下，它由这个简单表达式给出。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.chenqiaoqian.com/2023-07-22-Statistical.Modelling.of.Level.Difficulty.in.Puzzle.Games/8.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;请注意，从这个表达式中我们可以推导出（n，p）。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.chenqiaoqian.com/2023-07-22-Statistical.Modelling.of.Level.Difficulty.in.Puzzle.Games/9.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;还有另外两个显著的簇。第一个簇由p = 0.001定义，包括了15%的采样级别。这个簇中所有实例的共同特征是已达到参数拟合阈值，这将在第四节详细探讨。第二个簇由n &amp;gt; 200定义，包括了我们样本中的2%的级别。检查这个高n，高p的簇中的实例，我们遇到了要么是教程级别，要么是具有特定游戏机制的级别，这些机制引导玩家进行相对受限制的游戏玩法。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.chenqiaoqian.com/2023-07-22-Statistical.Modelling.of.Level.Difficulty.in.Puzzle.Games/10.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;图6. Kolmogorov-Smirnov检验统计量D和拟合分布均值的对数对数图。颜色显示了预期完成率与实际完成率之间的相对差异。&lt;/p&gt;
&lt;p&gt;值得注意的是，按设计，教程级别往往表现出比其他级别更低的方差，要么通过固定随机种子，要么通过整体布局和级别的理想策略。这种对随机性的降低可能导致移动分布的方差较小。同样，我们观察到，包含限制游戏玩法的引导机制的级别会导致玩体验不那么随机。这样的信息对级别设计者可能特别有用，因为创建完全由机会决定胜利机会的级别会剥夺玩家的主动性，可能并不是很有趣。因此，能够识别这样的级别可以提供对级别随机性的更量化度量。&lt;/p&gt;
&lt;h2 id=&#34;b-条件1和拟合的有效性&#34;&gt;B. 条件1和拟合的有效性 &lt;a href=&#34;#b-%e6%9d%a1%e4%bb%b61%e5%92%8c%e6%8b%9f%e5%90%88%e7%9a%84%e6%9c%89%e6%95%88%e6%80%a7&#34; class=&#34;anchor&#34;&gt;🔗&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;在第III-A节中提出的初始条件是，拟合分布F应该与经验分布Fˆ非常接近。为了确定这一点是否成立，我们使用由方程（1）定义的Kolmogorov-Smirnov距离D。为了概述分布参数和D之间的关系，图6绘制了D与拟合分布的均值（µ = n / (1−p)）之间的关系，并根据相对差异（c −cˆ）/cˆ进行着色。我们发现99%的级别满足D &amp;lt; 5%，这意味着在许多情况下拟合分布很好地描述了经验数据，因此满足了条件1。&lt;/p&gt;
&lt;p&gt;需要注意的一点是，在某些情况下，在拟合过程中达到了参数边界。观察到大约15%的级别发生了这种情况，通常导致p = 0.001。这些级别出现在图6中最右侧的簇中，其定义为µ &amp;gt; 103。当经验移动分布仅呈现稳定增长趋势时，通常会发生这种情况，导致仅使用分布的尾部最能描述这种简单行为的情况。我们认为这些示例由于方法未收敛而被视为拟合不良，并在接下来的分析中将其排除。在继续分析的下一部分之前，我们首先尝试分离显示良好拟合的级别与其他级别之间的差异。具体来说，我们首先调查不同的游戏机制是否会影响移动分布。为此，我们使用逻辑回归模型来建模级别拟合是否收敛，以估计特定棋子的影响。结果表明，计时机制通常会导致更好的拟合，而一个特定的生成机制（即，首次与生成器交互后目标出现）会导致拟合不佳。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.chenqiaoqian.com/2023-07-22-Statistical.Modelling.of.Level.Difficulty.in.Puzzle.Games/11.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;图7. 观察到的完成率与校准算法得到的拟合结果之间的比较。&lt;/p&gt;
&lt;p&gt;值得注意的是，用于此分析的数据忽略了使用各种游戏内辅助道具（例如额外移动、助推器等）的尝试。如果玩家发现某个级别很困难或令人沮丧，玩家后续的尝试可能会被忽略，因为他们使用了帮助道具，扭曲了移动分布。许多观察结果支持这一假设：当仅考虑玩家的第二次尝试的移动分布时，成功收敛的级别比例增加了约+5%。此外，在玩家使用游戏内助推器和辅助道具的尝试中，非收敛示例比收敛示例频率高出多达+18%；因此，对于非收敛示例，平均忽略的尝试更多。在我们的数据处理步骤中，这些尝试被过滤掉，因为它们显示出明显的曲线人为改变，特别是在级别的最后两个移动中。因此，对于拟合不一致的部分解释也可能与数据有关。&lt;/p&gt;
&lt;h2 id=&#34;c-条件2完成率比较&#34;&gt;C. 条件2：完成率比较 &lt;a href=&#34;#c-%e6%9d%a1%e4%bb%b62%e5%ae%8c%e6%88%90%e7%8e%87%e6%af%94%e8%be%83&#34; class=&#34;anchor&#34;&gt;🔗&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;&lt;img src=&#34;https://www.chenqiaoqian.com/2023-07-22-Statistical.Modelling.of.Level.Difficulty.in.Puzzle.Games/12.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;图8. 上方（a-c）和下方（d-f）的子图分别对应观察到的完成率ˆc&lt;code&gt; ≈ 20%和ˆc&lt;/code&gt; ≈ 40%的实例。
第一，第二和第三列分别举例说明了我们发现观察到的完成率和拟合完成率之间的好（a和d），中等（b和e）和低（c和f）一致性的情况。&lt;/p&gt;
&lt;p&gt;第二个条件规定，预期的完成率Fˆ(M∗)应接近观察到的完成率cˆ。为了评估这个条件，我们首先注意到这两个值有强烈的相关性，如它们的皮尔逊相关系数ρ = 83%所示。此外，图7暗示观察到的完成率和拟合完成率通过线性关系c ≈ 1.035ˆc - 0.104 (2)相互关联，调整后的决定系数R2 = 75%。公式(2)暗示完成率往往被低估，特别是在完成率低的情况下（即，对于非常困难的级别，平均玩家需要相当于8次或更多的尝试才能完成级别）。基于这些论点，我们可以认为条件2也得到了满足。&lt;/p&gt;
&lt;p&gt;在实践中，关卡设计师通常使用完成率的范围而不是点估计来工作，这样他们可以将关卡分类（例如，“简单”，“非常困难”）。因此，当前的结果是积极的，也很有希望。然而，人们也可以查看完成率的点估计，例如在绝对百分比误差ε := |c /ˆc - 1|的指导下。通过这样做，我们观察到ε的中位数大约是49%，并且根据公式（2）进行调整后，它降低到23%。
为了更好地理解导致上述低估（即，情况c &amp;lt; cˆ）的原因，我们在图8中举例说明了一系列场景中会发生什么：
场景1，如子图a和d所示，对应于ˆc和c之间的相对误差较小的情况。子图b和e中的场景2展示了误差中等的情况。最后，子图c和f中的场景3对应于大幅低估的情况。在场景3中，可以看到只用到了分布的尾部来描述数据。在拟合方法未收敛的情况下也观察到了类似的现象：由于可用的玩家数据和完成次数的稳步增加，只需要尾部就可以描述这种相对简单的行为。然而，与那些情况相反，这些级别更像是一个连续体：在完成率低的地方，更多的数据被审查，因此更可能低估，而对于更高的ˆc值（如场景1和场景2），我们有更多的关于分布的信息可用，这进一步限制了f。
为了看看是否有任何特定的游戏机制可能导致完成率之间的差异，使用了类似于第IV-B节的方法。而不是使用逻辑回归来预测是否拟合良好，而是使用线性回归来预测预期和实际完成率之间的差异。结果与前一节关于成功拟合的发现相似：具有时间或其他游戏限制机制的关卡导致更高的预期完成率。有趣的是，具有颜色匹配机制的棋盘部分往往导致过低的预期完成率。可能解释这一点的一种方法是，可以以稳定的速度完成的目标（如颜色机制）导致更稳步增加的坡度分布，由于在拟合中有更多的自由度，导致完全低估了完成率。另一方面，时间机制可能需要更多的规划，这可能表现为更受限制的最小移动次数，这导致围绕给定移动的分布更明确，而且方差更小，这可能对建模方法有害。也就是说，还有其他未考虑的因素（如关卡拓扑），因此需要更多的工作来建立完成率差异和游戏机制之间的任何联系。&lt;/p&gt;
&lt;h1 id=&#34;v-讨论和未来的工作&#34;&gt;V. 讨论和未来的工作 &lt;a href=&#34;#v-%e8%ae%a8%e8%ae%ba%e5%92%8c%e6%9c%aa%e6%9d%a5%e7%9a%84%e5%b7%a5%e4%bd%9c&#34; class=&#34;anchor&#34;&gt;🔗&lt;/a&gt;&lt;/h1&gt;&lt;p&gt;在85%的关卡中，我们能找到一个描述玩家数据的负二项分布。此外，我们能够推导出不同的游戏玩法特征的估计，如关卡随机性和棋盘部分描述符，这可以给游戏设计师提供额外的见解。也就是说，关于当前的建模方法和可能的使用情况，还有一些未解决的问题，这将在本节中讨论。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.chenqiaoqian.com/2023-07-22-Statistical.Modelling.of.Level.Difficulty.in.Puzzle.Games/13.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;图9. 二维图，展示了初始完成率和移动限制的变化如何影响预期的完成率变化。初始完成率被分成跨度为2%的区间，并根据图7的趋势调整新的预期完成率。&lt;/p&gt;
&lt;h2 id=&#34;a-改变移动限制&#34;&gt;A. 改变移动限制 &lt;a href=&#34;#a-%e6%94%b9%e5%8f%98%e7%a7%bb%e5%8a%a8%e9%99%90%e5%88%b6&#34; class=&#34;anchor&#34;&gt;🔗&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;讨论的一个用例是，通过建模这些分布，关卡设计师可以估计改变移动限制对完成率的影响。为了检查移动限制的变化如何影响完成率，图9显示了预期完成率的绝对变化如何取决于初始完成率和移动限制的变化。作为一个经验法则，完成率似乎平均变化2%，在高或低完成率时的敏感性略低。从与关卡设计师的讨论中，这与他们常用的启发式方法是一致的。
另一个见解是，增加或减少移动是一个不对称的操作，其中移动减少时的变化率更大。虽然这也是预期的，因为负二项分布本身可能是不对称的，并且可能有一个长的右尾（因此对增加移动的敏感度较低），但它表明，游戏设计师在移除时间或动作以增加难度时需要更加小心，因为这种不对称的变化。
这个论点的一个可能的局限性是，它假设如果移动限制改变，分布参数将保持不变。然而，这并不一定是真的，因为当玩家接近移动限制时，他们可能会改变他们的行为。例如，一个常见的策略是设置强大的棋盘组合，并在最后发动它们以最大化得分（无论是否有明确的得分）。&lt;/p&gt;
&lt;h2 id=&#34;b-玩家技能&#34;&gt;B. 玩家技能 &lt;a href=&#34;#b-%e7%8e%a9%e5%ae%b6%e6%8a%80%e8%83%bd&#34; class=&#34;anchor&#34;&gt;🔗&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;&lt;img src=&#34;https://www.chenqiaoqian.com/2023-07-22-Statistical.Modelling.of.Level.Difficulty.in.Puzzle.Games/14.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;图10. 某个AI代理完成特定的Lily&amp;rsquo;s Garden所使用的移动次数的直方图。虚线代表负二项分布的拟合。&lt;/p&gt;
&lt;p&gt;感知的关卡难度不仅取决于关卡的随机性，还取决于玩家的技能。到目前为止，关卡的随机性与拟合分布的方差有关，但从逻辑上讲，移动分布也应受到玩过该关卡的技能的影响。事实上，这是关卡设计师在日常工作中经常遇到的现象：随着更多的玩家达到更高的关卡，完成率慢慢变化，这使得需要对所有关卡进行持续的维护。
作为下一步，研究关卡难度如何在使用不同玩家群体的纵向研究中随时间变化，可能会对玩家技能提供有意义的见解，并模拟这如何影响分布参数。然后，这可以用于更主动和自动的难度调整方法，确保新老用户都有连贯的游戏体验。&lt;/p&gt;
&lt;h2 id=&#34;c-游戏测试&#34;&gt;C. 游戏测试 &lt;a href=&#34;#c-%e6%b8%b8%e6%88%8f%e6%b5%8b%e8%af%95&#34; class=&#34;anchor&#34;&gt;🔗&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;游戏测试对于游戏开发者至关重要，因为这个过程在产品上市前提供了一种在安全环境中识别错误和潜在设计缺陷的可靠方法。然而，这个过程往往如此昂贵和缓慢，以至于游戏开发者越来越开始通过使用AI代理来自动化这个过程，例如，使用强化学习技术（例如[12]及其中的参考文献）。这个背景也为深入了解本文中提出的技术以及进一步的潜在应用提供了一个有趣的设置。
实际上，考虑到游戏测试代理是在与人类玩家相同的环境中进行训练的，我们可以让代理使用所有的正常规则和游戏机制进行游戏，但不受移动限制M`的约束。图10显示了[13]中考虑的一个游戏测试代理在测试给定关卡时生成的移动分布。这个特定的代理在与平均人类玩家相比的表现是次优的，但重要的是我们能够可视化其整个移动分布，甚至超过限制M。因此，我们可以在整个（0，10M]范围内拟合我们提出的负二项分布，即，不进行截断。
符合我们的期望，我们得到了一个非常好的拟合，如Kolmogorov-Smirnov距离D = 1.8%所描述的那样。这引发了关于游戏测试代理的以下问题：展现出负二项分布是否可以被视为声明AI代理以人类的方式进行游戏的必要条件？
最后，我们强调与[13]中报告的结果的另一个联系。在那项工作中，作者报告说，代理在给定关卡上的5%最好的运行是实际完成率的最强预测因素。显然，这个5%的百分位数是可以从拟合的负二项参数中明确推导出来的量。从这个意义上说，我们还可以研究这里提出的拟合程序是否可以进一步用作后处理策略，从子人类甚至超人类表现的游戏测试代理生成的数据中估计完成率。&lt;/p&gt;
&lt;h2 id=&#34;d-其他游戏&#34;&gt;D. 其他游戏 &lt;a href=&#34;#d-%e5%85%b6%e4%bb%96%e6%b8%b8%e6%88%8f&#34; class=&#34;anchor&#34;&gt;🔗&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;在这项工作中，我们研究了将所提出的方法应用于移动益智游戏的情况；然而，在我们的假设中没有任何规定排除了同样的分布不仅可以用于具有离散移动和行动限制的类似益智游戏，还可以用于平台甚至竞技游戏等其他类型的游戏。
一般来说，益智游戏往往非常注重尽快解决关卡目标。虽然一些游戏也提供分数，但影响移动分布的因素（随机性和技能）数量有限。然而，在其他类型的游戏中，可能有其他的因素和激励来玩游戏：在平台游戏中，玩家被鼓励去探索和尝试不同的策略，而在竞技游戏中，玩家可能希望尽快击败对手，随机性的作用比玩家的相对技能小。因此，未来研究的一个有前景的方向是在各种类型的游戏中使用这种建模方法来测试和验证其对不同玩家行为的普遍适用性。&lt;/p&gt;
&lt;h1 id=&#34;vi-结论&#34;&gt;VI. 结论 &lt;a href=&#34;#vi-%e7%bb%93%e8%ae%ba&#34; class=&#34;anchor&#34;&gt;🔗&lt;/a&gt;&lt;/h1&gt;&lt;p&gt;在这项研究工作中，我们开始寻找一种更丰富的方式来描述益智游戏的关卡难度。具体来说，我们提出玩家完成一个关卡的移动频率分布遵循负二项分布。使用来自游戏Lily&amp;rsquo;s Garden的4000个关卡的数据作为案例研究，结果显示：
• 负二项分布能够描述大约85%的关卡的移动分布，而且这种方法可以轻易地扩展到其他类型的游戏。
• 可以使用一个参数——即规模参数ϑ——来描述分布的扩散，从而描述关卡。
• 这种更详细的难度描述使得：(i)估计改变移动限制的影响；(ii)估计关卡的随机性；和(iii)识别玩家在一个关卡上的行为偏差。
在剩下的大约15%的情况中，方法没有收敛；主要问题是由于数据只显示出增长趋势，这导致方法只使用分布的一小部分来匹配它。同样，该方法也倾向于低估观察到的完成率cˆ，特别是在完成率较低的情况下。因此，未来研究的一个可能的方向是扩展这个模型，并将cˆ作为建模的一个参数，而不是一个约束。这不仅有可能提高该方法的预测能力，而且最终可能实现估计玩家技能并动态调整难度，以确保最佳的玩家体验。&lt;/p&gt;
&lt;h1 id=&#34;vii-致谢&#34;&gt;VII. 致谢 &lt;a href=&#34;#vii-%e8%87%b4%e8%b0%a2&#34; class=&#34;anchor&#34;&gt;🔗&lt;/a&gt;&lt;/h1&gt;&lt;p&gt;这项工作得到了丹麦创新基金和Tactile Games的支持。我们也感谢Arnau Escapa和Rasmus Berg Palm的富有成效的讨论。&lt;/p&gt;
&lt;h1 id=&#34;结论&#34;&gt;结论 &lt;a href=&#34;#%e7%bb%93%e8%ae%ba&#34; class=&#34;anchor&#34;&gt;🔗&lt;/a&gt;&lt;/h1&gt;&lt;p&gt;搬砖愉快！&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>基于深度神经网络预测游戏关卡难度-中文版</title>
      <link>https://www.chenqiaoqian.com/2023/07/21/2023-07-21-Predicting.Game.Level.Difficulty.Using.Deep.Neural.Networks/</link>
      <pubDate>Fri, 21 Jul 2023 11:13:34 +0800</pubDate>
      
      <guid>https://www.chenqiaoqian.com/2023/07/21/2023-07-21-Predicting.Game.Level.Difficulty.Using.Deep.Neural.Networks/</guid>
      <description>&lt;p&gt;作者SAMI PURMONEN&lt;/p&gt;
&lt;h1 id=&#34;摘要&#34;&gt;摘要 &lt;a href=&#34;#%e6%91%98%e8%a6%81&#34; class=&#34;anchor&#34;&gt;🔗&lt;/a&gt;&lt;/h1&gt;&lt;p&gt;我们探索了蒙特卡洛树搜索（MCTS）和深度学习在预测Candy Crush游戏关卡难度（以成功尝试次数衡量）中的应用。通过大量的游戏玩家数据，我们训练了一个深度神经网络（DNN）来预测游戏状态的移动。该DNN在Candy Crush的大量关卡中游玩，然后我们拟合了一个回归模型来从机器人的难度中预测人类玩家的难度。我们将我们的结果与MCTS机器人的结果进行了对比。结果表明，DNN可以在明显较短的时间内，做出与MCTS相当的游戏关卡难度估计。&lt;/p&gt;
&lt;h1 id=&#34;总结&#34;&gt;总结 &lt;a href=&#34;#%e6%80%bb%e7%bb%93&#34; class=&#34;anchor&#34;&gt;🔗&lt;/a&gt;&lt;/h1&gt;&lt;p&gt;我们探索了使用蒙特卡洛树搜索（MCTS）和深度学习来评估Candy Crush游戏关卡的难度。通过大量游戏数据，我们训练了一个深度神经网络（DNN）来预测从游戏关卡中的游戏动作。DNN在Candy Crush的各种关卡中进行游戏，我们构建了一个模型来预测从DNN难度中的人类玩家难度。我们将结果与MCTS进行了比较。我们的结果显示，DNN可以在显著较短的时间内做出与MCTS相当的评估。&lt;/p&gt;
&lt;h1 id=&#34;致谢&#34;&gt;致谢 &lt;a href=&#34;#%e8%87%b4%e8%b0%a2&#34; class=&#34;anchor&#34;&gt;🔗&lt;/a&gt;&lt;/h1&gt;&lt;p&gt;我想感谢计算机科学与通信学院（CSC）的Karl Meinke教授对我的毕业论文的指导。我要感谢来自King公司AI团队的Stefan Freyr，Erik Poromaa和Alex Nodet，没有他们，这篇毕业论文的完成将无法成为可能。我还要对来自King公司AI团队的John Pertoft，Philipp Eisen和Lele Cao一直对我的工作提供反馈表示感谢。我要感谢Olov Engwall教授对我的论文的审阅。&lt;/p&gt;
&lt;h1 id=&#34;第1章&#34;&gt;第1章 &lt;a href=&#34;#%e7%ac%ac1%e7%ab%a0&#34; class=&#34;anchor&#34;&gt;🔗&lt;/a&gt;&lt;/h1&gt;&lt;h2 id=&#34;引言&#34;&gt;引言 &lt;a href=&#34;#%e5%bc%95%e8%a8%80&#34; class=&#34;anchor&#34;&gt;🔗&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;玩游戏可能很有趣，但前提是游戏的难度不能太难也不能太简单。如果游戏太难，玩家会感到沮丧并停止玩游戏。如果游戏太简单，玩家会感到无聊并停止玩游戏。在游戏发布给玩家之前，预测游戏关卡的难度是困难的。如果没有任何技术工具，关卡设计师只能多次手动玩关卡，然后根据对关卡设计师来说的难度，去猜测它对一般玩家的难度。然而，手动玩游戏需要大量时间，这导致在发布前的迭代次数较少。
对于游戏公司和关卡设计师来说，拥有能够快速并准确预测游戏关卡难度的工具将非常有用。这对于像King的Candy Crush这样不断发布新关卡的游戏尤其重要。它可以让关卡设计师在发布前多次调整关卡，以保证其难度适中。&lt;/p&gt;
&lt;h2 id=&#34;11-机器人&#34;&gt;1.1 机器人 &lt;a href=&#34;#11-%e6%9c%ba%e5%99%a8%e4%ba%ba&#34; class=&#34;anchor&#34;&gt;🔗&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;预测游戏关卡难度的一种自动化方式是创建一个程序，一个机器人，按照某种策略来玩这个游戏。机器人可以多次玩一个关卡，并根据&amp;quot;每次成功所需的尝试次数&amp;quot;这样的难度度量标准，估计机器人觉得这个关卡有多难。如果我们让机器人玩很多关卡，然后估计每个关卡的机器人难度，我们可以比较这些难度与人类的难度，试图将机器人的难度与人类的难度关联起来。如果一关对人类来说相对困难，对机器人来说也相对困难；如果对人类来说相对容易，对机器人来说也相对容易，那么我们可能可以创建一个有效的回归模型，从机器人的难度中预测人类的难度。新关卡的难度可以通过让机器人多次玩这个关卡，测量机器人的难度，然后用预测模型从机器人的难度中预测人类的难度来预测。这样有很多种策略可以创建。&lt;/p&gt;
&lt;h3 id=&#34;111-手动启发式&#34;&gt;1.1.1 手动启发式 &lt;a href=&#34;#111-%e6%89%8b%e5%8a%a8%e5%90%af%e5%8f%91%e5%bc%8f&#34; class=&#34;anchor&#34;&gt;🔗&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;机器人可以使用的一种策略是手动启发式，这种策略会对可用的走法进行排名，然后选择最好的一种。这种启发式可以查看当前的游戏状态，以判断每个可用走法的吸引力。这种方法的缺点是它不具有通用性或可维护性。当游戏发生变化，例如引入新的游戏元素时，启发式需要进行更新。每个游戏都必须创建新的启发式。&lt;/p&gt;
&lt;h3 id=&#34;112-蒙特卡洛树搜索&#34;&gt;1.1.2 蒙特卡洛树搜索 &lt;a href=&#34;#112-%e8%92%99%e7%89%b9%e5%8d%a1%e6%b4%9b%e6%a0%91%e6%90%9c%e7%b4%a2&#34; class=&#34;anchor&#34;&gt;🔗&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;一种更通用的方法是蒙特卡洛树搜索（MCTS）。MCTS并不是创建一大套规则去决定一步走位的吸引力，而是使用仿真。MCTS会多次执行每一个走法，并试玩到最后，估计它通向成功的频率。这就不需要对游戏有任何知识，可以自动处理游戏改变的情况，或者被用在一个全新的游戏上。MCTS的缺点是它很慢，因为它需要模拟许多次游戏。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.chenqiaoqian.com/2023-07-21-Predicting.Game.Level.Difficulty.Using.Deep.Neural.Networks/1.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;113-深度神经网络&#34;&gt;1.1.3 深度神经网络 &lt;a href=&#34;#113-%e6%b7%b1%e5%ba%a6%e7%a5%9e%e7%bb%8f%e7%bd%91%e7%bb%9c&#34; class=&#34;anchor&#34;&gt;🔗&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;机器学习也可以用来从游戏状态中对走法进行排序，本质上是从数据中学习启发式。如果一个包含有游戏状态和走法的大型数据集可用，那么就可以在监督学习中使用，来训练一个分类器，预测在任何给定的游戏状态中应选择哪种走法。深度神经网络（DNN）就是一种可用于分类的机器学习算法，并已在图像识别、机器翻译和游戏中取得了重大突破。使用DNN从游戏状态中预测走法将比MCTS快得多，因为它不需要进行模拟，同时也具有通用性，因为只需要新的数据集就能学习一个新的游戏。不解的问题是它是否也具有精确性。这就是本论文中將要探讨的问题。
表1.1显示了这些方法在假设上相互比较的情况。&lt;/p&gt;
&lt;h2 id=&#34;12-问题&#34;&gt;1.2 问题 &lt;a href=&#34;#12-%e9%97%ae%e9%a2%98&#34; class=&#34;anchor&#34;&gt;🔗&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;我们的研究问题是，在Candy Crush游戏中，使用深度神经网络（DNN）机器人是否可以比使用蒙特卡洛树搜索（MCTS）机器人更好地预测游戏关卡的难度。&lt;/p&gt;
&lt;h2 id=&#34;13-界定范围&#34;&gt;1.3 界定范围 &lt;a href=&#34;#13-%e7%95%8c%e5%ae%9a%e8%8c%83%e5%9b%b4&#34; class=&#34;anchor&#34;&gt;🔗&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;我们将研究范围限制在King的游戏Candy Crush，以及使用由MCTS机器人生成的训练数据。&lt;/p&gt;
&lt;h1 id=&#34;第2章&#34;&gt;第2章 &lt;a href=&#34;#%e7%ac%ac2%e7%ab%a0&#34; class=&#34;anchor&#34;&gt;🔗&lt;/a&gt;&lt;/h1&gt;&lt;h2 id=&#34;相关理论&#34;&gt;相关理论 &lt;a href=&#34;#%e7%9b%b8%e5%85%b3%e7%90%86%e8%ae%ba&#34; class=&#34;anchor&#34;&gt;🔗&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;在本章中，我们提供我们工作基础的理论基础。我们深入研究了神经网络的工作原理和训练方式，因为这是本论文最重要的部分，也是工作的大部分投入时间所在。&lt;/p&gt;
&lt;h2 id=&#34;21-相关工作&#34;&gt;2.1 相关工作 &lt;a href=&#34;#21-%e7%9b%b8%e5%85%b3%e5%b7%a5%e4%bd%9c&#34; class=&#34;anchor&#34;&gt;🔗&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;主要的灵感来源于谷歌DeepMind的AlphaGo论文和Erik Poromaas的硕士论文。其他的灵感来源于图像识别，因为从游戏状态预测着法的问题可以看作是一个图像识别问题。更广泛的灵感来源于与机器学习或游戏人工智能有关的任何内容。
在《利用深度神经网络和树搜索掌握围棋》中，发明了一款使用监督学习、强化学习和蒙特卡罗树搜索的计算机围棋程序。这是第一个能够在全尺寸棋盘上击败专业围棋选手的计算机围棋程序[1]。我们的工作受到AlphaGo的监督学习部分的启发，但我们将其用于预测游戏难度，而不是创建最强大的机器人。
在Candy Crush中，Erik Poromaa使用MCTS预测Candy Crush中的游戏水平难度。他发现这种方法优于先前的最先进的手动测试方法[2]。我们将我们的结果与他创建的MCTS机器人进行了比较。
在《利用深度卷积神经网络进行ImageNet分类》中，一个大型深度卷积神经网络在数百万高分辨率图像上进行训练，显著提高了以前在ImageNet LSVRC-2010比赛中的最新技术水平[3]。尽管这里的目标是确定图像中可见的对象类型，但与我们的问题类似，因为游戏棋盘可以被视为一个具有比RGB更多通道的图像，并且我们试图识别的对象是144个可能移动中的一个，因此卷积神经网络也适合我们的问题。
在《利用深度卷积神经网络在围棋中进行着法评估》中，一个12层的深度卷积神经网络在人类职业围棋选手的数据集上进行训练，用于预测着法。它以55%的准确率预测专业着法，并且可以击败传统的搜索程序而无需进行任何搜索[4]。这篇论文启发了AlphaGo，并与我们所做的非常相似，因为他们创建了一个基于仅监督学习的DNN机器人进行围棋比赛，然而我们进一步采取了一步，使用机器人来预测游戏难度。
在《使用卷积神经网络在国际象棋中预测着法》中，训练了一个深度卷积神经网络来预测国际象棋中的着法。国际象棋的问题在于一步着法由棋子移动的位置定义，因此需要一个分类器来区分64*64或4096种不同的着法。为了减少着法数量，他们采用了一种新颖的方法，创建了两个独立网络，一个用于预测移动哪个棋子，另一个用于预测在哪里移动它，从而将每个网络的类空间减少到64。他们成功以38.3%的准确率预测哪个棋子应该移动[5]。他们的目标是预测着法与我们的目标相同，只是我们不需要在减少类空间方面下一番苦功，因为我们问题中的着法数量是可管理的，而在围棋中有361种着法。
在《使用深度强化学习在Atari中玩游戏》中，创建了一个基于卷积神经网络和强化学习的模型来玩七款Atari 2600游戏。它在六款游戏中优于先前的所有方法，并在其中三款游戏中表现优于人类专家[6]。应用类似的强化方法到我们的问题可能会很有趣，但我们决定选择监督学习，因为我们认为预测游戏难度的最佳方法是创建一个模仿人类玩家的机器人。由于在本论文写作时我们没有人类玩家数据，因此无法实现这一目标，但可以在未来进行尝试。&lt;/p&gt;
&lt;h2 id=&#34;22-蒙特卡洛树搜索&#34;&gt;2.2 蒙特卡洛树搜索 &lt;a href=&#34;#22-%e8%92%99%e7%89%b9%e5%8d%a1%e6%b4%9b%e6%a0%91%e6%90%9c%e7%b4%a2&#34; class=&#34;anchor&#34;&gt;🔗&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;在创建玩游戏的代理程序时，通常会使用不同的游戏树搜索算法。极小化算法是一种树搜索算法，在棋类游戏如国际象棋、跳棋和奥赛洛中已经达到了最先进的性能，那里有用于评估游戏状态的良好启发式[1]。在围棋等很难提出启发式的游戏中，直到AlphaGo出现之前，MCTS一直是最成功的游戏搜索算法[4]。
MCTS通过使用随机抽样来扩展搜索树，从状态中确定最佳行动。它可应用于任何有限长度和有限移动次数的游戏。每个行动都是搜索树中的一个节点，并记录获胜次数和访问次数，这些数据用于引导搜索树朝着更好的走法发展。它由四个迭代执行的步骤组成：选择、扩展、模拟和回传，如图2.1所示。多次执行这些步骤会收敛到最佳的玩法[7]。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.chenqiaoqian.com/2023-07-21-Predicting.Game.Level.Difficulty.Using.Deep.Neural.Networks/2.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;选择&lt;/strong&gt;
选择从当前状态开始，也就是搜索树的根节点，然后选择子节点，直到达到叶子节点。选择子节点的方式是根据获胜次数和访问次数，但同时也允许探索，以便将树扩展为朝着最有希望的走法。
&lt;strong&gt;扩展&lt;/strong&gt;
当到达叶子节点时，如果游戏尚未结束，则会向搜索树添加一个新的子节点。
&lt;strong&gt;模拟&lt;/strong&gt;
通过随机选择行动对游戏进行模拟直到结束。
&lt;strong&gt;回传&lt;/strong&gt;
游戏结果通过所有访问过的节点回传到根节点，更新获胜次数和访问次数。&lt;/p&gt;
&lt;h2 id=&#34;23-机器学习&#34;&gt;2.3 机器学习 &lt;a href=&#34;#23-%e6%9c%ba%e5%99%a8%e5%ad%a6%e4%b9%a0&#34; class=&#34;anchor&#34;&gt;🔗&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;机器学习涵盖了从经验中学习的算法。监督学习是机器学习中最常见的形式。监督学习算法从这类映射的训练集示例中学习函数F：R^N → R^M，然后它在未见数据上的预测效果变得更好，这意味着它在泛化。&lt;/p&gt;
&lt;h3 id=&#34;231-分类&#34;&gt;2.3.1 分类 &lt;a href=&#34;#231-%e5%88%86%e7%b1%bb&#34; class=&#34;anchor&#34;&gt;🔗&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;分类意味着将有限类别集C中的类别c分配给输入特征。例如，我们可以有一个分类器，输入一个人的身高和体重，输出c ∈ {男性, 女性}。给定一组标记为女性或男性的人的体重和身高数据集，学习算法可以生成一个预测人们性别的分类器。分类器的目的是在未见数据上使用它，因此在训练期间的目标是训练一个泛化到未见数据的分类器。
&lt;strong&gt;数据表示&lt;/strong&gt;
分类器的输入是一个向量X ∈ R^n，其中n是特征数量。分类器的输出是一个向量Y ∈ R^c，其中c是类别数量，Y_i是第i类的分数。预测的类别是arg max_i Y_i。Y可以被归一化，使得P i Y_i = 1，将其成为给定类别的条件概率分布P(i|X) = Y_i，使用softmax函数表示如2.1方程所示。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.chenqiaoqian.com/2023-07-21-Predicting.Game.Level.Difficulty.Using.Deep.Neural.Networks/3.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.chenqiaoqian.com/2023-07-21-Predicting.Game.Level.Difficulty.Using.Deep.Neural.Networks/4.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;这是我们在本论文中对分类的看法。这是一种从输入向量生成所有可能类别的概率分布的方法。&lt;/p&gt;
&lt;h3 id=&#34;232-人工神经网络&#34;&gt;2.3.2 人工神经网络 &lt;a href=&#34;#232-%e4%ba%ba%e5%b7%a5%e7%a5%9e%e7%bb%8f%e7%bd%91%e7%bb%9c&#34; class=&#34;anchor&#34;&gt;🔗&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;神经网络是一种监督学习算法。我们将讨论它如何用于分类任务。神经网络由相互连接的神经元层组成，具有权重。我们将讨论前馈神经网络，其中第i层的神经元仅连接到第i + 1层的神经元，如图2.2所示。神经网络中具有后向连接的神经元称为循环神经网络，在对时间敏感的语音识别中非常有用。人工神经元在某种程度上模仿大脑内的生物神经元。然而，我们将把它们视为数学单元，因为与生物学的联系并不会使人们更容易理解它们的工作方式，除非有生物学背景。&lt;/p&gt;
&lt;h4 id=&#34;从输入到输出&#34;&gt;从输入到输出 &lt;a href=&#34;#%e4%bb%8e%e8%be%93%e5%85%a5%e5%88%b0%e8%be%93%e5%87%ba&#34; class=&#34;anchor&#34;&gt;🔗&lt;/a&gt;&lt;/h4&gt;&lt;p&gt;用于分类的神经网络接收一个输入向量X ∈ R^n，并输出一个向量Y ∈ R^c，代表可能类别的概率分布，如第2.3.1节所述。神经网络与其他分类器的不同之处在于它的工作方式。接下来我们将讨论这一点。&lt;/p&gt;
&lt;h4 id=&#34;神经元的工作&#34;&gt;神经元的工作 &lt;a href=&#34;#%e7%a5%9e%e7%bb%8f%e5%85%83%e7%9a%84%e5%b7%a5%e4%bd%9c&#34; class=&#34;anchor&#34;&gt;🔗&lt;/a&gt;&lt;/h4&gt;&lt;p&gt;每个神经元对每个输入特征都有一个权重和一个偏差。它计算其输入的加权和，其中包括来自前一层的激活，如方程2.2所示，并应用激活函数。激活函数背后的思想是，神经元具有二进制输出，即它要么发射，要么不发射。每个神经元会检测来自前几层的输入中的模式，并在检测到模式时发射。它还在网络中引入非线性，这对于能够逼近非线性函数是必要的。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.chenqiaoqian.com/2023-07-21-Predicting.Game.Level.Difficulty.Using.Deep.Neural.Networks/5.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;常见的激活函数是Sigmoid，如方程2.3所示。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.chenqiaoqian.com/2023-07-21-Predicting.Game.Level.Difficulty.Using.Deep.Neural.Networks/6.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;另一个常见的激活函数是TanH。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.chenqiaoqian.com/2023-07-21-Predicting.Game.Level.Difficulty.Using.Deep.Neural.Networks/7.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;反向传播使用损失函数的梯度来更新神经网络的权重，因此如果梯度变得非常小，更新将变小，学习速度变慢。Sigmoid和tanh都存在梯度消失的问题，因为它们将输入映射到一个小范围内。方程2.5中显示的修正线性单元是另一个激活函数，它在处理梯度消失方面问题较少，因为它仅将负值截断为零。它训练速度是几倍快于Sigmoid和TanH，因为它不会饱和，意味着输出没有上限，可以变得任意大。它目前是深度学习中最流行的激活函数。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.chenqiaoqian.com/2023-07-21-Predicting.Game.Level.Difficulty.Using.Deep.Neural.Networks/8.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;当输入被截断为零时，修正线性单元存在问题，因为这会使梯度变为零，无法进行学习。方程2.6中显示的指数线性单元(ELU)被引入来解决这个问题，允许负值存在。然而，与ReLU相比，ELU计算成本更高。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.chenqiaoqian.com/2023-07-21-Predicting.Game.Level.Difficulty.Using.Deep.Neural.Networks/9.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;成本函数&#34;&gt;成本函数 &lt;a href=&#34;#%e6%88%90%e6%9c%ac%e5%87%bd%e6%95%b0&#34; class=&#34;anchor&#34;&gt;🔗&lt;/a&gt;&lt;/h4&gt;&lt;p&gt;为了改进神经网络，必须有一个客观的衡量标准来评估网络的表现好坏。这通过成本函数来实现。如果网络的输出接近期望输出，则成本较低，否则成本较高。一个常用的成本函数是均方误差，如方程2.7所示。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.chenqiaoqian.com/2023-07-21-Predicting.Game.Level.Difficulty.Using.Deep.Neural.Networks/10.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;另一个常用的成本函数是交叉熵，它具有显著的实际优势，因为在权重随机初始化时可以找到更好的局部最优解[10, 11]。使用交叉熵成本函数而不是均方误差，结合softmax激活函数会导致更准确的结果[12]。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.chenqiaoqian.com/2023-07-21-Predicting.Game.Level.Difficulty.Using.Deep.Neural.Networks/11.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.chenqiaoqian.com/2023-07-21-Predicting.Game.Level.Difficulty.Using.Deep.Neural.Networks/12.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;网络通过计算成本函数并更新其权重来学习，以最小化成本函数。因此，学习过程本质上是一个优化问题。成本函数是权重的函数。为了最小化它，使用梯度下降。梯度下降计算成本函数相对于权重的梯度。然后，它沿着相反的方向更新权重，使成本变小，如2.9所示。权重之间的差异大小由学习率决定。在实践中，对大量数据使用梯度下降不可行，因此改用随机梯度下降，仅使用训练数据的一个小子集来计算成本函数的估计值，这样可以加快训练时间 [13]。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.chenqiaoqian.com/2023-07-21-Predicting.Game.Level.Difficulty.Using.Deep.Neural.Networks/13.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;当神经网络进行训练时，它学习到应具有的权重。影响训练的参数，如网络架构，但在训练过程中不会学习的参数被称为超参数。神经网络有很多超参数。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;学习率&lt;/li&gt;
&lt;li&gt;隐藏层的数量&lt;/li&gt;
&lt;li&gt;隐藏节点的数量&lt;/li&gt;
&lt;li&gt;激活函数的选择&lt;/li&gt;
&lt;li&gt;错误测量的选择&lt;/li&gt;
&lt;li&gt;学习率衰减&lt;/li&gt;
&lt;li&gt;正则化&lt;/li&gt;
&lt;li&gt;初始权重&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;这些可以通过手动测试不同组合来决定。选择它们的更严谨的方法是使用网格搜索或随机搜索。在网格搜索中，为每个参数选择一个有限的值集合，然后尝试所有组合。产生最高准确性的组合被选为最佳参数组合。随机搜索是随机选择参数，已经显示比网格搜索更有效 [14]。基因算法通过结合先前成功的组合来培育新的组合，也可以被应用。一种基于强化学习的新颖方法，利用验证集上的验证准确性作为反馈生成架构，已被证明能够生成与CIFAR-10数据集上最佳人工设计的架构媲美的架构 [15]。&lt;/p&gt;
&lt;h3 id=&#34;233-卷积神经网络&#34;&gt;2.3.3 卷积神经网络 &lt;a href=&#34;#233-%e5%8d%b7%e7%a7%af%e7%a5%9e%e7%bb%8f%e7%bd%91%e7%bb%9c&#34; class=&#34;anchor&#34;&gt;🔗&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;卷积神经网络（CNN）已经显著改善了物体识别，并且是目前此任务的最新技术 [16]。在CNN中，每个神经元连接在重叠的瓦片中，使网络在二维空间中具有局部性。这对可以被视为图像或网格的输入数据效果很好 [16]。
&lt;strong&gt;输入&lt;/strong&gt;
将输入数据视为三维向量，而不是一维向量。一个尺寸为9×9的rgb图像将具有尺寸为9×9×3，因为它有3个颜色通道。
&lt;strong&gt;块大小&lt;/strong&gt;
块大小决定一个神经元覆盖的面积有多大。3×3的块是最常见的大小，意味着第i+1层中的每个神经元都连接到第i层中一个3×3的神经元瓦片。
&lt;strong&gt;步幅&lt;/strong&gt;
步幅确定输入之间每个到滤波器的距离。
&lt;strong&gt;滤波器&lt;/strong&gt;
滤波器的数量决定每一层中可以检测到多少特征，因为滤波器共享权重。
&lt;strong&gt;池化&lt;/strong&gt;
通过总结其输入来减小输入的维度。例如，一个2×2的最大池化将会接收一个2×2的输入，输出一个1×1，输出值为输入中的最高值，并跨数据进行步进。&lt;/p&gt;
&lt;h2 id=&#34;24-candy-crush&#34;&gt;2.4 Candy Crush &lt;a href=&#34;#24-candy-crush&#34; class=&#34;anchor&#34;&gt;🔗&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;Candy Crush是一款在2012年发布在Facebook上的流行的三消游戏，后来在多个平台上推出。由于在开发超过2000个关卡过程中不断添加新功能，该游戏变得非常复杂。因此，我们不会提供游戏的完整描述，而是将读者引向在线可用的Candy Crush维基百科。我们将描述对论文有趣的基础知识。&lt;/p&gt;
&lt;h3 id=&#34;241-基本游戏玩法&#34;&gt;2.4.1 基本游戏玩法 &lt;a href=&#34;#241-%e5%9f%ba%e6%9c%ac%e6%b8%b8%e6%88%8f%e7%8e%a9%e6%b3%95&#34; class=&#34;anchor&#34;&gt;🔗&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;基本的游戏玩法包括在一个9x9的游戏板上水平或垂直交换相邻的瓦片，使得三个或三个以上的相同颜色糖果形成水平或垂直排列。这就是为什么它被称为三消游戏。如果忽略方向，有144种独特的交换组合，其中72种垂直和72种水平。&lt;/p&gt;
&lt;p&gt;匹配的糖果将从游戏板上移除，如果匹配了三个以上的糖果，将会生成特殊糖果，如图2.5所示。特殊糖果比普通糖果更强大，因为它们在匹配时不仅会移除自身，还会移除其他糖果。制作特殊糖果因此是游戏策略中的重要部分。还有多种类型的阻碍物，如结霜，可能存在于一个瓦片上，使得在清除结霜之前，无法与下面的糖果匹配。&lt;/p&gt;
&lt;p&gt;解决游戏是NP难题。状态空间在不同关卡之间不同，但是很大，实验显示第13关的状态空间约为10182。&lt;/p&gt;
&lt;h3 id=&#34;242-游戏模式&#34;&gt;2.4.2 游戏模式 &lt;a href=&#34;#242-%e6%b8%b8%e6%88%8f%e6%a8%a1%e5%bc%8f&#34; class=&#34;anchor&#34;&gt;🔗&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;有五种不同类型的关卡，具有不同的目标。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;限时关卡：在时间耗尽之前达到特定分数&lt;/li&gt;
&lt;li&gt;分数关卡：在固定次数的移动内达到特定分数&lt;/li&gt;
&lt;li&gt;订单关卡：在固定次数的移动内清除所有订单，一个订单可能是清除90个红色糖果&lt;/li&gt;
&lt;li&gt;组合关卡：完成其他目标的组合&lt;/li&gt;
&lt;li&gt;配料关卡：在固定次数的移动内清除所有配料&lt;/li&gt;
&lt;li&gt;凝胶关卡：在固定次数的移动内清除所有凝胶
具有不同策略要求的多种游戏模式使得游戏对AI更具挑战性。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://www.chenqiaoqian.com/2023-07-21-Predicting.Game.Level.Difficulty.Using.Deep.Neural.Networks/14.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.chenqiaoqian.com/2023-07-21-Predicting.Game.Level.Difficulty.Using.Deep.Neural.Networks/15.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h1 id=&#34;第3章&#34;&gt;第3章 &lt;a href=&#34;#%e7%ac%ac3%e7%ab%a0&#34; class=&#34;anchor&#34;&gt;🔗&lt;/a&gt;&lt;/h1&gt;&lt;h2 id=&#34;方法&#34;&gt;方法 &lt;a href=&#34;#%e6%96%b9%e6%b3%95&#34; class=&#34;anchor&#34;&gt;🔗&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;在本章中，我们详细描述了我们的方法。它分为两部分，即在简化版本的糖果上进行的实验和在糖果上进行的实验。&lt;/p&gt;
&lt;h2 id=&#34;31-简化版糖果&#34;&gt;3.1 简化版糖果 &lt;a href=&#34;#31-%e7%ae%80%e5%8c%96%e7%89%88%e7%b3%96%e6%9e%9c&#34; class=&#34;anchor&#34;&gt;🔗&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;当论文开始时，我们还没有来自糖果的训练数据，并且我们希望在简化问题上探索深度学习，以了解它对我们问题空间的强大性和适用性。因此，我们决定：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;构建一个简化版的糖果&lt;/li&gt;
&lt;li&gt;创建一个确定性贪婪机器人&lt;/li&gt;
&lt;li&gt;从贪婪机器人玩糖果中生成数据集&lt;/li&gt;
&lt;li&gt;训练一个深度神经网络（DNN）&lt;/li&gt;
&lt;li&gt;评估分类性能
由于我们没有任何关于简化版糖果的人类难度数据，因此我们在这个实验中不尝试预测难度。我们只探讨分类任务。&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;311-简化版糖果&#34;&gt;3.1.1 简化版糖果 &lt;a href=&#34;#311-%e7%ae%80%e5%8c%96%e7%89%88%e7%b3%96%e6%9e%9c&#34; class=&#34;anchor&#34;&gt;🔗&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;简化版糖果是用C++实现的，可以带有或不带有GUI进行游玩。如图3.1所示。与真实游戏的9×9相比，它有一个略小的8×8游戏板。它有5种不同的糖果颜色而不是6种。它没有特殊糖果或阻碍物。它没有特定目标。游戏在60秒后自动停止，得分与清除的糖果数量成比例增加。新的糖果会从均匀分布中随机生成。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.chenqiaoqian.com/2023-07-21-Predicting.Game.Level.Difficulty.Using.Deep.Neural.Networks/16.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.chenqiaoqian.com/2023-07-21-Predicting.Game.Level.Difficulty.Using.Deep.Neural.Networks/17.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;312-确定性贪婪机器人&#34;&gt;3.1.2 确定性贪婪机器人 &lt;a href=&#34;#312-%e7%a1%ae%e5%ae%9a%e6%80%a7%e8%b4%aa%e5%a9%aa%e6%9c%ba%e5%99%a8%e4%ba%ba&#34; class=&#34;anchor&#34;&gt;🔗&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;我们创建了一个确定性贪婪机器人，它总是选择能清除最多糖果的移动。它总是更喜欢进行五连消而不是四连消，四连消而不是三连消。如果有多个移动能够清除相同数量的糖果，它更倾向于水平交换而不是垂直交换，并且更喜欢西北位置而不是东南位置。这使得机器人是确定性的，可以从任何游戏板上计算出它将选择的移动。这很重要，因为数据变得100%可预测，这意味着机器学习者可以获得100%的验证准确率。当从非确定性策略学习时，这是不可能的，您无法知道理论上的最大验证准确率是多少。&lt;/p&gt;
&lt;h3 id=&#34;313-生成数据集&#34;&gt;3.1.3 生成数据集 &lt;a href=&#34;#313-%e7%94%9f%e6%88%90%e6%95%b0%e6%8d%ae%e9%9b%86&#34; class=&#34;anchor&#34;&gt;🔗&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;我们从确定性贪婪机器人玩简化版糖果中生成了一个数据集。数据集仅有两个特征平面，一个用于颜色，一个用于有效移动。每种颜色被编码为 0 ≤ c ≤ 4。有效移动特征平面是二进制的，对游戏板上的每个位置进行编码，表示该位置是否可以成为有效移动的一部分，意味着该单元格中的糖果可以交换并成为三连消的一部分。
由于游戏板有 board_size 行，每行有 board_size - 1 个水平交换（如果忽略交换的方向），所以一共有 board_size * (board_size - 1) 个水平交换。由于水平交换和垂直交换一样多，总交换次数为 2 * board_size * (board_size - 1)。对于这个特定的数据集，board_size = 8，因此有 2 * 8 * 7 = 112 种不同的交换。因此，一个移动被编码为一个数字，范围在 0 ≤ n ≤ 111，如图3.4所示。
数据集以CSV文件的形式存储。每一行对应一个数据点。前 2 * 8 * 8 = 128 个数字是特征，包含每个游戏板位置的两个特征平面，最后一个数字是移动。&lt;/p&gt;
&lt;h3 id=&#34;314-神经网络架构&#34;&gt;3.1.4 神经网络架构 &lt;a href=&#34;#314-%e7%a5%9e%e7%bb%8f%e7%bd%91%e7%bb%9c%e6%9e%b6%e6%9e%84&#34; class=&#34;anchor&#34;&gt;🔗&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;网络架构是通过手动实验决定的。我们本来希望在许多参数组合上执行网格搜索，但我们认为这样做太耗时且计算成本太高，在这项工作中并不切实可行。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.chenqiaoqian.com/2023-07-21-Predicting.Game.Level.Difficulty.Using.Deep.Neural.Networks/18.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;我们选择使用卷积神经网络，因为我们的游戏板具有网格结构，并且在其他棋盘游戏（如围棋）上表现出色[1]。由于从MCTS机器人生成数据需要很长时间，所以在调整超参数时我们使用了比最终评估时更小的数据集。我们测试了不同数量的卷积层，发现超过三层不会提高验证准确性，反而会增加过拟合。池化操作通常用于减少输入维度，在图像识别中经常使用，例如图像大小为256x256。我们选择不使用池化操作，因为我们的9x9游戏板已经很小。&lt;/p&gt;
&lt;h3 id=&#34;315-神经网络评估&#34;&gt;3.1.5 神经网络评估 &lt;a href=&#34;#315-%e7%a5%9e%e7%bb%8f%e7%bd%91%e7%bb%9c%e8%af%84%e4%bc%b0&#34; class=&#34;anchor&#34;&gt;🔗&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;数据集被分成训练集和验证集。训练集用于在训练过程中更新网络的权重。验证集用于评估。在训练过程中使用的性能衡量标准是验证准确性，如方程3.1所示。我们还计算了验证前2准确性和验证前3准确性，即在前2和前3个移动中正确移动被找到的频率。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.chenqiaoqian.com/2023-07-21-Predicting.Game.Level.Difficulty.Using.Deep.Neural.Networks/19.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;验证准确度并不是游戏策略的完美衡量标准，因为游戏状态中选择的动作是非确定性的，这意味着在某个游戏状态下，同一个玩家可能多次选择不同的动作。如果玩家在一个具有10个合法动作的状态下，以50%的概率选择其中一个动作，那么理论上的最大验证准确性将会是50%；但如果网络学习了正确的概率分布，它将完美地学习了游戏策略。理想情况是使用测量实际和预测概率分布之间距离的方法，而不是像方程3.2中所示的验证准确度，比如Kullback-Leibler散度。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.chenqiaoqian.com/2023-07-21-Predicting.Game.Level.Difficulty.Using.Deep.Neural.Networks/20.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;然而，由于状态空间非常大，很少有来自特定状态的多个训练样本，使得在特定状态下估计概率分布变得不可能。因此，出于务实原因选择了验证准确性。在没有其他基准的情况下，这被比较为随机选择每个游戏状态中移动的预期准确性，计算如方程3.3所示，其中Si是状态i中可用的移动数。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.chenqiaoqian.com/2023-07-21-Predicting.Game.Level.Difficulty.Using.Deep.Neural.Networks/21.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;32-糖果&#34;&gt;3.2 糖果 &lt;a href=&#34;#32-%e7%b3%96%e6%9e%9c&#34; class=&#34;anchor&#34;&gt;🔗&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;对糖果进行的实验包括以下步骤：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;从一个MCTS机器人玩糖果中生成数据集。&lt;/li&gt;
&lt;li&gt;训练一个DNN。&lt;/li&gt;
&lt;li&gt;使用DNN和MCTS玩不同的糖果关卡，并评估性能，以累积成功率和平均成功率作为衡量标准。&lt;/li&gt;
&lt;li&gt;评估表现，以累积成功率和平均成功率为指标进行测量。&lt;/li&gt;
&lt;li&gt;创建回归模型，从以尝试次数为单位的机器人难度测量人类难度来预测。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;就像对简化版糖果一样，我们生成训练数据，然后训练神经网络，随后使用神经网络实际进行游戏，并根据成功率衡量机器人的表现，并创建一个模型来预测人类难度，其中机器人难度以每次成功尝试的次数来衡量。&lt;/p&gt;
&lt;h3 id=&#34;321-蒙特卡洛树搜索&#34;&gt;3.2.1 蒙特卡洛树搜索 &lt;a href=&#34;#321-%e8%92%99%e7%89%b9%e5%8d%a1%e6%b4%9b%e6%a0%91%e6%90%9c%e7%b4%a2&#34; class=&#34;anchor&#34;&gt;🔗&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;使用的MCTS算法由King提供。它是基于C++编写的，建立在糖果源代码的基础之上。这个实现有一些新颖之处。与其只使用胜利或失败作为信号不同，我们使用基于部分目标的连续信号，比如清除的果冻数量和/或得分。我们将其视为一个黑盒子，可以在模拟游戏过程中配置为使用训练过的DNN，因此不需要更详细的描述，但在Erik Poromaas的硕士论文中有更多信息。&lt;/p&gt;
&lt;h3 id=&#34;322-生成数据集&#34;&gt;3.2.2 生成数据集 &lt;a href=&#34;#322-%e7%94%9f%e6%88%90%e6%95%b0%e6%8d%ae%e9%9b%86&#34; class=&#34;anchor&#34;&gt;🔗&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;由于我们希望使用神经网络来预测玩家的难度，最合理的做法是使用玩家的游戏数据。然而，该数据并不可用，我们无法在论文中获取到。我们有一个可以很好地玩游戏的MCTS机器人。我们让这个MCTS机器人在每次移动时使用1000次模拟游戏来玩一个多样化的关卡集，这些关卡从第1000关到第2000关，并在游戏过程中记录所有的（状态，动作）对，以CSV格式直接用于训练神经网络。我们收集了接近200万个数据点。其中50,000个数据点用于验证，其余用于训练。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;数据表示&lt;/strong&gt;
特征平面包括：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;可用的水平移动次数&lt;/li&gt;
&lt;li&gt;可用的垂直移动次数&lt;/li&gt;
&lt;li&gt;缺失的瓷砖&lt;/li&gt;
&lt;li&gt;糖果颜色 - 随机&lt;/li&gt;
&lt;li&gt;糖果颜色 - 无&lt;/li&gt;
&lt;li&gt;糖果 - 蓝色&lt;/li&gt;
&lt;li&gt;糖果 - 绿色&lt;/li&gt;
&lt;li&gt;糖果 - 橙色&lt;/li&gt;
&lt;li&gt;糖果 - 紫色&lt;/li&gt;
&lt;li&gt;糖果 - 红色&lt;/li&gt;
&lt;li&gt;糖果 - 黄色&lt;/li&gt;
&lt;li&gt;糖果颜色数&lt;/li&gt;
&lt;li&gt;果冻&lt;/li&gt;
&lt;li&gt;障碍物&lt;/li&gt;
&lt;li&gt;锁定物&lt;/li&gt;
&lt;li&gt;普通类型的板块物品&lt;/li&gt;
&lt;li&gt;行类型的板块物品&lt;/li&gt;
&lt;li&gt;列类型的板块物品&lt;/li&gt;
&lt;li&gt;包装类型的板块物品&lt;/li&gt;
&lt;li&gt;热门类型的板块物品&lt;/li&gt;
&lt;li&gt;炸弹类型的板块物品&lt;/li&gt;
&lt;li&gt;瑞典鱼类型的板块物品&lt;/li&gt;
&lt;li&gt;食材类型的板块物品 - 樱桃&lt;/li&gt;
&lt;li&gt;食材类型的板块物品 - 榛果&lt;/li&gt;
&lt;li&gt;时间补充类型的板块物品&lt;/li&gt;
&lt;li&gt;辣椒糖果类型的板块物品&lt;/li&gt;
&lt;li&gt;甘草糖果类型的板块物品&lt;/li&gt;
&lt;li&gt;椰子轮类型的板块物品&lt;/li&gt;
&lt;li&gt;王牌类型的板块物品&lt;/li&gt;
&lt;li&gt;神秘糖果类型的板块物品&lt;/li&gt;
&lt;li&gt;变色糖果类型的板块物品&lt;/li&gt;
&lt;li&gt;青蛙类型的板块物品&lt;/li&gt;
&lt;li&gt;榛子类型的板块物品&lt;/li&gt;
&lt;li&gt;不明飞行物类型的板块物品 - UFO&lt;/li&gt;
&lt;li&gt;板块物品类型数&lt;/li&gt;
&lt;li&gt;剩余移动次数&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&#34;https://www.chenqiaoqian.com/2023-07-21-Predicting.Game.Level.Difficulty.Using.Deep.Neural.Networks/22.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;颜色被编码为单独的二进制特征平面，与简化的数据集不同，在简化的数据集中只有一个颜色特征平面，不同的颜色使用不同的数字。这样做更有意义，因为颜色只有分类意义。有效移动的特征平面被划分为水平移动和垂直移动两部分。这并不会造成任何差异，因为神经网络能够学习两种表示。移动的编码与第一个实验中的相同，只是更大的游戏板面使得0 ≤ n ≤ 143，而不是如图3.5中的0 ≤ n ≤ 111。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;缺点&lt;/strong&gt;
虽然在简化版的糖果游戏中移动的方向并不重要，但在糖果游戏中却很重要。当匹配两种特殊糖果时，对游戏板的影响会因方向的不同而不同。为了捕捉到这种情况，我们需要区分288种移动，而不是144种。这可能使得学习到需要特定的特殊糖果和方向组合才能过关的高级策略变得不可能。然而，我们注意到我们有50%的概率能够在最佳的方向进行交换，并且两个相邻的条纹糖果并不是一个常见的情况，所以我们决定丢弃方向，因为如果类别增加一倍，会使得训练DNN变得更加困难。
数据集还有其他一些缺点。最大的一个是没有关于关卡目标的特征平面。如果目标是清理果冻，数据中并未包含需要清理的果冻数量，如果目标是清理材料，那么也没有包含剩余需要清理的材料数量的特征平面。这可能会使网络在剩余移动次数较少的情况下，难以学会优先考虑目标，而不是创建花哨的特殊糖果。&lt;/p&gt;
&lt;h3 id=&#34;323-dnn架构&#34;&gt;3.2.3 DNN架构 &lt;a href=&#34;#323-dnn%e6%9e%b6%e6%9e%84&#34; class=&#34;anchor&#34;&gt;🔗&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;我们使用与简单糖果游戏相同的DNN。&lt;/p&gt;
&lt;h3 id=&#34;324-使用dnn&#34;&gt;3.2.4 使用DNN &lt;a href=&#34;#324-%e4%bd%bf%e7%94%a8dnn&#34; class=&#34;anchor&#34;&gt;🔗&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;因为我们认为使用不成熟的TensorFlow C++ API将其嵌入到MCTS C++源代码中过于繁琐，所以我们通过用Python编写的HTTP服务器使用DNN。让HTTP服务器在与机器人相同的物理机器上运行，使得网络开销微乎其微。
我们试验让DNN独自玩游戏以及在MCTS播放过程中玩游戏。根据DNN选择最有可能的移动。&lt;/p&gt;
&lt;h3 id=&#34;325-神经网络评估&#34;&gt;3.2.5 神经网络评估 &lt;a href=&#34;#325-%e7%a5%9e%e7%bb%8f%e7%bd%91%e7%bb%9c%e8%af%84%e4%bc%b0&#34; class=&#34;anchor&#34;&gt;🔗&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;对于简单的糖果游戏，训练的评估方式相同。我们总共使用了4个机器人进行比较。机器人也与人类玩家进行比较。我们比较了机器人的累积成功率，以衡量他们的表现。我们还拟合了模型，以预测从机器人每个成功的尝试次数中预测人类每个成功的尝试次数，以衡量它们的预测力。MCTS每个级别执行100次尝试，DNN每个级别执行100和1000次尝试，因为它的速度更快。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;随机机器人&lt;/strong&gt;
随机机器人从均匀分布中随机选择动作。这是默认的基线。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;DNN机器人&lt;/strong&gt;
DNN机器人根据深度神经网络选择最可能的动作。它不进行任何搜索。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.chenqiaoqian.com/2023-07-21-Predicting.Game.Level.Difficulty.Using.Deep.Neural.Networks/23.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;MCTS + 随机机器人&lt;/strong&gt;
MCTS + 随机机器人使用随机回放的MCTS。它作为MCTS + DNN机器人的基线。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;MCTS + DNN机器人&lt;/strong&gt;
MCTS + DNN机器人在回放过程中使用MCTS，其中根据DNN选择最可能的动作。&lt;/p&gt;
&lt;h3 id=&#34;326-预测模型&#34;&gt;3.2.6 预测模型 &lt;a href=&#34;#326-%e9%a2%84%e6%b5%8b%e6%a8%a1%e5%9e%8b&#34; class=&#34;anchor&#34;&gt;🔗&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;我们让机器人玩361个级别，以计算机器人试错次数的难度。我们让每个机器人对每个级别尝试100次，除了DNN，我们允许其尝试1000次，因为它的速度更快。这些级别的玩家数据是可用的，所以我们也可以计算人类每次成功的尝试次数。机器人的难度并不等同于人类的难度，但它们是相关的。我们拟合了一个回归模型来预测机器人尝试成功次数到人类尝试成功次数。我们使用平均绝对误差作为预测精度的度量，这直观地表示预测的平均错误程度。&lt;/p&gt;
&lt;p&gt;我们将级别分为三组，绿色，黄色和红色，根据他们对每个级别的难度，因为我们看到人类每次成功的尝试次数和机器人每次成功的尝试次数的关系，对于更简单的级别和更困难的级别是不同的。我们为每个机器人的每个组拟合一个单独的预测模型。绿色级别的尝试成功率低于或等于预选的割值。黄色级别的成功尝试次数高于割值。红色级别有零成功，所以尝试次数是未定义的。我们使用人类每次成功尝试的平均值作为红色级别的预测值。&lt;/p&gt;
&lt;h2 id=&#34;33-软件&#34;&gt;3.3 软件 &lt;a href=&#34;#33-%e8%bd%af%e4%bb%b6&#34; class=&#34;anchor&#34;&gt;🔗&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;我们使用深度学习库TensorFlow来实现DNN。Google创造了TensorFlow来替代在Google内部广泛使用的DistBelief [18]。TensorFlow是用C++编写的，API在Python中可用。它不像其他如Torch和Theano[19]等可用的深度学习库那么快，但有很多有用的工具。TensorBoard是一个可视化训练的Web界面。在创建TensorFlow图时，可以添加用于记录如验证精度、交叉熵和学习率等测量值的节点。TensorBoard可以在训练中动态创建的图中显示登记的测量值，如图3.7所示。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.chenqiaoqian.com/2023-07-21-Predicting.Game.Level.Difficulty.Using.Deep.Neural.Networks/24.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;34-硬件&#34;&gt;3.4 硬件 &lt;a href=&#34;#34-%e7%a1%ac%e4%bb%b6&#34; class=&#34;anchor&#34;&gt;🔗&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;我们使用了来自亚马逊网络服务的一个g2.8xlarge GPU服务器用于训练神经网络。它具有：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;4个GPU&lt;/li&gt;
&lt;li&gt;32个vCPU&lt;/li&gt;
&lt;li&gt;60 GiB内存&lt;/li&gt;
&lt;li&gt;2x120 SSD存储&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;游戏在具有未知规格的虚拟机上运行。&lt;/p&gt;
&lt;h1 id=&#34;第4章&#34;&gt;第4章 &lt;a href=&#34;#%e7%ac%ac4%e7%ab%a0&#34; class=&#34;anchor&#34;&gt;🔗&lt;/a&gt;&lt;/h1&gt;&lt;h2 id=&#34;结果&#34;&gt;结果 &lt;a href=&#34;#%e7%bb%93%e6%9e%9c&#34; class=&#34;anchor&#34;&gt;🔗&lt;/a&gt;&lt;/h2&gt;&lt;h2 id=&#34;41-训练神经网络&#34;&gt;4.1 训练神经网络 &lt;a href=&#34;#41-%e8%ae%ad%e7%bb%83%e7%a5%9e%e7%bb%8f%e7%bd%91%e7%bb%9c&#34; class=&#34;anchor&#34;&gt;🔗&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;这部分展示了在训练过程中DNN的表现。验证精度显示了DNN在未见过的数据上预期的表现。我们还包括了正确的动作在前2和前3中出现的频率。训练的最终结果和使用的数据集的详细信息显示在表4.1中。训练期间的验证精度的图示显示在图4.1和图4.2中。&lt;/p&gt;
&lt;p&gt;在简化的数据集上的验证精度很高，如表4.1所示，达到了92.2%。如果给出更多的数据，更多的训练时间和更大的模型，它可能会变得更好。可能接近100%。&lt;/p&gt;
&lt;p&gt;在MCTS数据上的验证精度要低得多，只有28.3%。这并不奇怪，因为它是由一个非确定性的算法生成的。28.3%依然比随机猜测的16.3%要高很多。考虑到我们不知道MCTS数据的可预测性如何，很难知道我们的网络在学习它方面的表现如何。可能是30%是理论上的最高验证精度，如果是这样，那么28.3%就是很好的结果，或者可能会更高，如果是这样，那么28.3%可能就不太好了。为了了解DNN在学习像MCTS那样玩游戏的情况如何，我们需要用DNN玩游戏，并比较它和MCTS的表现。我们将在下一节中做这个。&lt;/p&gt;
&lt;p&gt;训练精度在图表中跳动较大。这是因为它是在128个随机选择的数据点上计算的。对于两个数据集，训练精度似乎接近验证精度。这意味着神经网络没有过拟合，说明还有增加模型大小的空间。我们本来会做这个，但是时间不够。在论文工作期间，我们不断地收集更多的数据，直到最后一个数据集足够大，也就没有过拟合。&lt;/p&gt;
&lt;p&gt;看着验证，验证前-2和验证前-3的精度，我们注意到，在MCTS数据上训练的DNN从28.3%提高到44.4%，再提高到57.3%。这意味着即使它没有选择正确的动作，正确的动作往往也在前3之内。考虑到在糖果游戏中有许多情况，多种动作看起来同样好，如果很难在它们之间区分也就不足为奇了。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.chenqiaoqian.com/2023-07-21-Predicting.Game.Level.Difficulty.Using.Deep.Neural.Networks/25.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;图4.1：简化糖果游戏的验证精度。验证前2意味着正确的动作在预测的前2个中的频率，验证前3意味着正确的动作在预测的前3个中的频率。训练精度是在128个数据点的小批量上计算的。&lt;/p&gt;
&lt;p&gt;表4.1：简化糖果游戏和糖果游戏的神经网络训练结果。随机精度是从每个游戏状态的可用移动中随机选择时所期望的验证精度。训练精度是在训练数据的一个小型批次上计算的。验证前-2精度和验证前-3精度意味着正确的动作在预测动作的前-2和前-3中的频率。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.chenqiaoqian.com/2023-07-21-Predicting.Game.Level.Difficulty.Using.Deep.Neural.Networks/26.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.chenqiaoqian.com/2023-07-21-Predicting.Game.Level.Difficulty.Using.Deep.Neural.Networks/27.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;图4.2：糖果游戏的验证精度。验证前2意味着正确的动作在预测的前2个中的频率，验证前3意味着正确的动作在预测的前3个中的频率。训练精度是在128个数据点的小批量上计算的。&lt;/p&gt;
&lt;h2 id=&#34;42-机器人性能&#34;&gt;4.2 机器人性能 &lt;a href=&#34;#42-%e6%9c%ba%e5%99%a8%e4%ba%ba%e6%80%a7%e8%83%bd&#34; class=&#34;anchor&#34;&gt;🔗&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;我们使用图4.3中显示的所有等级的累积成功率来比较机器人的强度，数值越高越好。
在不进行任何搜索的情况下，深度神经网络(DNN)的表现优于随机选择，如图4.3所示，在进行模拟过程中使用DNN可以提高蒙特卡洛树搜索(MCTS)的性能。这证明了DNN已经从数据中学到了游戏的有用知识，但肯定还有很多没有学到。值得注意的是，纯粹的DNN的表现与纯粹的MCTS相比差很多，而其他人已经成功地使DNN在围棋中的表现与MCTS一样强。围棋的结果是使用专家的动作实现的，而我们使用的数据是来自于比专家玩家更弱的MCTS机器人。训练数据的问题之一是它没有包含游戏的目标。出于这个原因，如果不进行任何搜索，表现好就将变得困难。使用搜索与不使用搜索之间的改进要大于使用DNN与不使用DNN之间的改进。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.chenqiaoqian.com/2023-07-21-Predicting.Game.Level.Difficulty.Using.Deep.Neural.Networks/28.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;43-难度预测&#34;&gt;4.3 难度预测 &lt;a href=&#34;#43-%e9%9a%be%e5%ba%a6%e9%a2%84%e6%b5%8b&#34; class=&#34;anchor&#34;&gt;🔗&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;表4.2显示了每个机器人在361个级别的平均绝对误差。这显示了模型从机器人的难度中预测人类难度的能力有多好。
最令人惊讶的结果是，尽管深度神经网络(DNN)比蒙特卡洛树搜索(MCTS)弱很多，但是当它被允许在每个级别尝试1000次而不是100次时，它在预测人类难度方面却和MCTS差不多，或者更好，可以在表4.2中看到。当DNN在每个级别只做100次尝试时，它是最差的预测器。由于DNN比MCTS快得多，所以它可以在比MCTS做100次尝试的时间更短的时间内做1000次尝试。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.chenqiaoqian.com/2023-07-21-Predicting.Game.Level.Difficulty.Using.Deep.Neural.Networks/29.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h1 id=&#34;第5章-讨论与结论&#34;&gt;第5章 讨论与结论 &lt;a href=&#34;#%e7%ac%ac5%e7%ab%a0-%e8%ae%a8%e8%ae%ba%e4%b8%8e%e7%bb%93%e8%ae%ba&#34; class=&#34;anchor&#34;&gt;🔗&lt;/a&gt;&lt;/h1&gt;&lt;h2 id=&#34;51-实践的有效性&#34;&gt;5.1 实践的有效性 &lt;a href=&#34;#51-%e5%ae%9e%e8%b7%b5%e7%9a%84%e6%9c%89%e6%95%88%e6%80%a7&#34; class=&#34;anchor&#34;&gt;🔗&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;深度神经网络（DNN）如果被允许进行1000次尝试而不是100次，它能做出与蒙特卡洛树搜索（MCTS）相似的难度预测，这是一个在实践中有实用性的结果。这意味着在几分钟内，而不是几个小时，就可以得到与人类难度相似的估计。这可以改变关卡设计师的工作流程，给他们提供更快的反馈循环，使他们在发布前有可能做出更多的调整。&lt;/p&gt;
&lt;h2 id=&#34;52-方法在candy-crush以外的适用性&#34;&gt;5.2 方法在Candy Crush以外的适用性 &lt;a href=&#34;#52-%e6%96%b9%e6%b3%95%e5%9c%a8candy-crush%e4%bb%a5%e5%a4%96%e7%9a%84%e9%80%82%e7%94%a8%e6%80%a7&#34; class=&#34;anchor&#34;&gt;🔗&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;我们用来预测Candy Crush游戏难度的方法也应该适用于其他游戏。游戏需要有一个有限的动作空间，这样就可以将其解释为一个分类问题，而且由于我们只是看当前的游戏状态来选择一个动作，所以动作的选择必须只依赖于当前的游戏状态，而不是前一状态。在King公司，我们在两个其他的游戏中也应用了相同的方法，但是那些游戏与Candy Crush非常相似。这种方法对频繁发布新关卡的游戏最有用。&lt;/p&gt;
&lt;h2 id=&#34;53-深度神经网络和蒙特卡洛树搜索对比&#34;&gt;5.3 深度神经网络和蒙特卡洛树搜索对比 &lt;a href=&#34;#53-%e6%b7%b1%e5%ba%a6%e7%a5%9e%e7%bb%8f%e7%bd%91%e7%bb%9c%e5%92%8c%e8%92%99%e7%89%b9%e5%8d%a1%e6%b4%9b%e6%a0%91%e6%90%9c%e7%b4%a2%e5%af%b9%e6%af%94&#34; class=&#34;anchor&#34;&gt;🔗&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;DNN方法的主要优势是速度，可以在极短的时间内做出相似的难度预测。DNN的另一个好处是，它可以在人类的游戏数据上进行训练，使其能像人类一样游戏，可能导致更精确的预测。DNN的主要劣势是，它需要游戏数据和重新训练。对于每一个新的游戏，都必须创建一个游戏状态表示并收集数据。每当游戏添加新的游戏元素时，DNN就必须进行重新训练，并收集新的数据以保持精度。MCTS不需要任何关于游戏版面的知识，因此相同的算法可以应用于新的游戏，无需修改。&lt;/p&gt;
&lt;h2 id=&#34;54-人工智能的伦理学&#34;&gt;5.4 人工智能的伦理学 &lt;a href=&#34;#54-%e4%ba%ba%e5%b7%a5%e6%99%ba%e8%83%bd%e7%9a%84%e4%bc%a6%e7%90%86%e5%ad%a6&#34; class=&#34;anchor&#34;&gt;🔗&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;人工智能（AI）存在两个主要关注点。一是超级智能的威胁，二是自动化的经济影响。
&lt;strong&gt;超级智能&lt;/strong&gt;
人工智能可根据其强大的程度分为三种类别。目前所有的AI都处于人工狭义智能（ANI）的类别，也就是说它是特定任务。深蓝（DeepBlue)比任何人都擅长下棋，但下棋是它能做的全部。第二个类别是人工普遍智能（AGI），包括大约与人类一样能力的AI，也就是说它能做人类可以做的普通事情。第三类是人工超智能（ASI），包括超过人类的AI。一旦AGI被发明出来，它可能能够递归地改进其软件以使其更有能力，最终达到ASI [20]。如果ASI变得恶性，它可能会将人类消灭。在这篇论文中，我们探讨了ANI的另一种应用，它在当前状态下并不对人类的生存构成威胁。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;经济影响&lt;/strong&gt;
能以更低的价格取代人类劳动的AI会导致失业，至少在冗余的工人找到替代工作的时候是暂时的 [21]。一些工人可能会发现很难转换到新的职业，因为他们可能没有或者不能获得需要的技能。这篇论文可能会使游戏的人工测试者变得多余和失业。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;环境影响&lt;/strong&gt;
所述方法需要在云服务器上使用计算能力和存储，但让一个计算机程序在几秒钟内玩一个级别应该比让一个人在几分钟内玩它有更小的环境影响，因此我们认为，用自动化解决方案成功地替换人工玩家对环境是有好处的。&lt;/p&gt;
&lt;h2 id=&#34;55-未来的工作&#34;&gt;5.5 未来的工作 &lt;a href=&#34;#55-%e6%9c%aa%e6%9d%a5%e7%9a%84%e5%b7%a5%e4%bd%9c&#34; class=&#34;anchor&#34;&gt;🔗&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;改进架构&lt;/strong&gt;
由于我们受到时间的严重限制，我们并没有对可能的神经网络的空间进行过多的探索。有几乎无尽的事物可以试验。如果有时间的话，用更多的数据训练更深层的DNN可能会显示出更好的结果。我们并没有在我们的架构中出现过拟合，所以训练一个更深层次的DNN将是下一步要尝试的事情。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;改进数据&lt;/strong&gt;
我们使用的数据排除了重要信息，如关卡的目标。它也没有包含移动的方向。使用更优质的数据可能会显示出更好的结果。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;真实用户数据&lt;/strong&gt;
我们最初打算在这篇论文中使用真实用户的数据。我们花了很多时间收集《糖果粉碎苏打传奇》的数据，这需要向代码库添加代码并发布。然而，由于回放游戏的问题超出了我们的控制范围，这一任务不得不中止。继续进行这个实验，对专家玩家进行训练，并观察这对性能有何影响，将是一个有趣的话题。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;强化学习&lt;/strong&gt;
在这篇论文中，我们只尝试让神经网络学习别人如何玩，本例中是一个MCTS Bot。被最小化的性能指标是神经网络能多好地预测别人如何玩。将目标改为尽量打好可能是个有趣的尝试。使用强化学习，可以在对数据集进行训练后修改DNN的权重，以便最大化其性能。玩一关，看看它的表现如何，更新权重，让它下次玩得更好。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;学习的定性探索&lt;/strong&gt;
我们只对性能进行了定量度量。神经网络学习了什么样的动作和策略？我们并不清楚，我们只知道它达到了一定的验证精度，而且它在游戏中有一定的成功率。探究它学习了哪些动作，没有学习哪些动作，可能会给出一些有趣的见解。&lt;/p&gt;
&lt;h2 id=&#34;56-结论&#34;&gt;5.6 结论 &lt;a href=&#34;#56-%e7%bb%93%e8%ae%ba&#34; class=&#34;anchor&#34;&gt;🔗&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;我们研究了使用基于深度神经网络(DNN)的机器人玩《糖果粉碎传奇》游戏以预测游戏水平难度，并将其与基于蒙特卡洛树搜索(MCTS)的机器人进行了对比。我们在MCTS机器人生成的数据上训练了DNN。DNN机器人比MCTS机器人弱得多，但它可以用来在更短的时间内做出与MCTS机器人相当的人类难度预测。DNN也可以通过在决策过程中使用，而不是随机决策，来使MCTS机器人更强大，但由此做出的人类难度预测并没有更准确。最重要的三个结论是：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;MCTS比DNN强大得多&lt;/li&gt;
&lt;li&gt;如果在游戏过程中使用DNN，可以使MCTS更强大&lt;/li&gt;
&lt;li&gt;DNN可以在大大缩短的时间内做出与人类难度相当的预测&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;参考文献&#34;&gt;参考文献 &lt;a href=&#34;#%e5%8f%82%e8%80%83%e6%96%87%e7%8c%ae&#34; class=&#34;anchor&#34;&gt;🔗&lt;/a&gt;&lt;/h1&gt;&lt;p&gt;[1] David Silver, Aja Huang, Christopher J. Maddison, Arthur Guez, Laurent Sifre, George van den Driessche, Julian Schrittwieser, Ioannis Antonoglou, Veda Panneershelvam, Marc Lanctot, Sander Dieleman, Dominik Grewe, John Nham, Nal Kalchbrenner, Ilya Sutskever, Timothy Lillicrap, Madeleine Leach, Koray Kavukcuoglu, Thore Graepel 和 Demis Hassabis. 利用深度神经网络和树搜索掌握围棋。《自然》杂志, 529:484–503, 2016。网址http://www.nature.com/nature/journal/v529/n7587/full/nature16961.html。
[2] Erik Poromaa. 《粉碎糖果传奇》的胜利。硕士论文, 皇家工学院, 2016。
[3] Alex Krizhevsky, Ilya Sutskever, 和 Geoffrey E Hinton. 利用深度卷积神经网络进行Imagenet分类。在神经信息处理系统进展中, 页码1097–1105, 2012。
[4] Chris J. Maddison, Aja Huang, Ilya Sutskever, 和 David Silver. 利用深度卷积神经网络在围棋中进行着法评估。CoRR, abs/1412.6564, 2014。网址http://arxiv.org/abs/1412.6564。
[5] Barak Oshri 和 Nishith Khandwala. 使用卷积神经网络预测国际象棋中的着法。
[6] Volodymyr Mnih, Koray Kavukcuoglu, David Silver, Alex Graves, Ioannis Antonoglou, Daan Wierstra, 和 Martin Riedmiller. 使用深度强化学习玩Atari游戏。arXiv预印本arXiv:1312.5602, 2013。
[7] Levente Kocsis 和 Csaba Szepesvári. 基于赌徒蒙特卡罗规划的带头臂策略。在机器学习欧洲会议上, 页码282–293。Springer, 2006。
[8] Yann LeCun, Yoshua Bengio, 和 Geoffrey Hinton. 深度学习。《自然》, 521(7553):436–444, 2015。
[9] Djork-Arné Clevert, Thomas Unterthiner, 和 Sepp Hochreiter. 通过指数线性单元（ELUs）快速准确地学习深度网络。CoRR, abs/1511.07289, 2015。网址http://arxiv.org/abs/1511.07289。
[10] Pavel Golik, Patrick Doetsch, 和 Hermann Ney. 交叉熵与平方误差训练：理论和实验比较。在Interspeech中, 页码1756–1760, 2013。
[11] Douglas M Kline 和 Victor L Berardi. 重新审视用于训练神经网络分类器的平方误差和交叉熵函数。神经计算与应用, 14(4):310–318, 2005。
[12] Rob A Dunne 和Norm A Campbell. 关于softmax激活和交叉熵惩罚函数配对以及softmax激活函数的推导。在第8届澳大利亚神经网络会议论文集中, 墨尔本, 181, 卷185, 1997。
[13] Michael A. Nielsen.《神经网络与深度学习》。Determination Press, 2015。
[14] James Bergstra 和Yoshua Bengio. 超参数优化的随机搜索。《机器学习研究杂志》, 13(Feb):281–305, 2012。
[15] Barret Zoph 和Quoc V. Le. 利用强化学习进行神经网络架构搜索。CoRR, abs/1611.01578, 2016。网址http://arxiv.org/abs/1611.01578。
[16] Christian Szegedy, Wei Liu, Yangqing Jia, Pierre Sermanet, Scott Reed, Dragomir Anguelov, Dumitru Erhan, Vincent Vanhoucke, 和 Andrew Rabinovich. 使用卷积进一步深入。在IEEE计算机视觉与模式识别大会论文集中, 页码1–9, 2015。
[17] Toby Walsh. 糖果传奇是NP难题。CoRR, abs/1403.1911, 2014。网址http://arxiv.org/abs/1403.1911。
[18] Martín Abadi, Paul Barham, Jianmin Chen, Zhifeng Chen, Andy Davis, Jeffrey Dean, Matthieu Devin, Sanjay Ghemawat, Geoffrey Irving, Michael Isard, 等. TensorFlow: 一个大规模机器学习系统。在第12届USENIX操作系统设计与实现研讨会（OSDI）论文集中。美国乔治亚州萨凡纳, 2016。
[19] Soheil Bahrampour, Naveen Ramakrishnan, Lukas Schott, 和Mohak Shah. 深度学习软件框架的比较研究。arXiv预印本arXiv:1511.06435, 2015。
[20] Nick Bostrom. 超级智能出现前需要多长时间？1998。
[21] Nils J Nilsson. 人工智能、就业和收入。《人工智能杂志》，5(2):5, 1984。&lt;/p&gt;
&lt;h1 id=&#34;结论&#34;&gt;结论 &lt;a href=&#34;#%e7%bb%93%e8%ae%ba&#34; class=&#34;anchor&#34;&gt;🔗&lt;/a&gt;&lt;/h1&gt;&lt;p&gt;搬砖愉快！&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>
